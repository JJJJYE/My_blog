---
title: "Various Method for Time Series Data"
description: |
  Compare Various Method for Time Series Data
author:
  - name: Yeongeun Jeon
  - name: Jung In Seo
date: 06-07-2020
preview: preview.PNG
categories: Time Series
output: 
  distill::distill_article:
        toc: TRUE
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


- Data 출처 : [Data Mining for Business Analytics](https://www.dataminingbook.com/book/r-edition)에서 사용한 미국 철도 회사 “Amtrak”에서 수집한 1991년 1월~2004년 3월까지 매달 환승 고객 수

-----------

# **Introduction**

- Ridership on Amtrak Trains(미국 철도 회사 “Amtrak”에서 수집한 1991년 1월~2004년 3월까지 매달 환승 고객 수) 예제를 이용하여 시계열에 적용가능한 여러 방법들이 실제 데이터에 어떻게 적용되는지 설명한다.
  - [Regression][**2.1 Regression**]
  - [Dynamic linear model][**2.2 Dynamic linear model(DLM)**]
  - [Bootstrap and Bagging][**2.3 Bootstrap and Bagging**]
  - [Neural network][**2.4 Neural network**]
- 적용된 방법들 중 어느 방법이 예측과 적합이 잘 되었는지 비교한다.


# **1. Data**

- `ggplot()`을 위해서 data의 구조는 데이터프레임으로 바꿔주었다.

```{r, echo=FALSE}
pacman::p_load("data.table",
               "forecast",
               "ggplot2",
               "dplyr",
               "xts",
               "dlm")

# Data 불러오기

 Amtrak.data <- fread(paste(getwd(),"Amtrak.csv", sep="/"))
         
```

```{r}
# Create time series

ridership.ts <- ts(Amtrak.data$Ridership, start=c(1991,1), end=c(2004,3), freq=12)


# Decompose train data and validation data

train.ts <- window(ridership.ts,start=c(1991,1), end=c(2001,3))
valid.ts <- window(ridership.ts,start=c(2001,4))
nValid   <- length(valid.ts)

# Create Data.frame for ggplot
                 
xts(ridership.ts, order = as.Date(ridership.ts))
ridership_df            <- as.data.frame(ridership.ts)
names(ridership_df)     <- "Observation"
ridership_df$Date       <- as.Date(ridership.ts)  # Add Date column in last
cln                     <- ncol(ridership_df)
ridership_df            <- ridership_df[, c(cln, 1:(cln-1))]  # Change the order of the column. That is first column "Date"
row.names(ridership_df) <- NULL


head(ridership_df)
```


```{r}
   
# Plot the series
   
ggplot(data=ridership_df, aes(x=Date, y=Observation)) + geom_line() +
labs(y="Ridership") +
scale_x_date(breaks =  seq(as.Date("1991-01-01"), as.Date("2004-03-01"), by="2 year")) + theme_minimal() 

```

- 그래프를 보면 추세와 계절성이 동시에 존재하는 비정상성 시계열이다.


# **2. Models**

## **2.1 Regression**


### **2.1.1 모형 적합과 예측**


- 먼저 `forecast` package에 있는 `tslm()` 함수를 이용하여 추세와 계절성이 동시에 존재하는 회귀모형을 적합시켜보았다.
- 추세는 U자형으로 2차함수 형태의 추세를 고려하였다.
 

```{r}
train.lm.trend.season <- tslm(train.ts ~ trend + I(trend^2) + season)  # Fit Trend + Seasonality Model
summary(train.lm.trend.season)
 
```

```{r}

train.lm.trend.season.pred <- forecast(train.lm.trend.season, h=nValid, level=0) # Forecast
train.lm.trend.season.pred

head(train.lm.trend.season.pred)
```


```{r}
Acf(train.lm.trend.season$residuals, lag.max = 12, main="") 
```


- 모형 적합 후 잔차의 자기상관 그래프를 보면 잔차들이 독립이 아닌 것을 볼 수 있다.
   - 잔차는 white noise로써 독립을 만족해야한다.
- 정상성 시계열로 데이터를 변형하는 것보다 잔차에 회귀모형을 적합시키는 것은 데이터 변형을 필요로 하지 않는다.
   - 잔차의 자기상관 그래프가 시차가 1일 때 강한 양의 자기상관을 보이며 지수적으로 감소하기에 AR(1) 모형을 적합시킨다.
- 잔차에 회귀모형을 적합시킴으로써 예측값을 향상시킬 수 있다.
   - 짧은 기간의 예측에 유용하다.
   

```{r}
# Fit AR(1) model to training residuals

train.res.arima <- Arima(train.lm.trend.season$residuals, order=c(1,0,0))
summary(train.res.arima)

```

```{r}
train.res.arima.pred <- forecast(train.res.arima, h=nValid, level=0)
train.res.arima.pred

head(train.res.arima.pred)
```



```{r}
plot(train.lm.trend.season$residuals, ylim=c(-250,250), ylab="Residuals", xlab="Time", bty="l", xaxt="n", xlim=c(1991,2006.25), main="")
axis(1, at=seq(1991,2006,1), labels=format(seq(1991,2006,1)))
lines(train.res.arima.pred$fitted, lwd=2, col="blue")
 
```

```{r}
Acf(train.res.arima$residuals, lag.max = 12)
```


- 잔차에 AR(1) 모형이 잘 적합되었음을 알 수 있다.

### **2.1.2 향상된 예측값**

- 예측은 `forecast()` function을 이용한다.
   - 향상된 예측값은 데이터에 대한 모형의 예측값과 AR(1) 모형이 적합된 잔차의 예측값을 더하여 얻을 수 있다. 


```{r}
# Improved forecast(Forecast of the fiited model + Forecast of AR(1) model of residuals)

res.arima         <- as.data.frame(train.res.arima.pred)[,1]
fore              <- as.data.frame(train.lm.trend.season.pred)[,1]
Improved_forecast <- apply(cbind(res.arima,fore), 1,sum)

head(Improved_forecast)

Improved_forecast <- ts(Improved_forecast, start=c(2001,4), end=c(2004,3), freq=12)  # Convert as time-series

```

### **2.1.3 그래프**

```{r}
# Plot for regression based on forecast 

 regression <- ridership_df %>% mutate("Fitted"= c(train.lm.trend.season$fitted,Improved_forecast)) # Combine original data and fitted data


ggplot(data=regression, aes(x=Date, y=Observation)) + geom_line(aes(color="Data", size="Data", linetype="Data")) + 
geom_line(aes(x=Date, y=Fitted, colour="Fitted model", size="Fitted model", linetype="Fitted model")) + 
scale_color_manual(name="",values=c("Data"="black", "Fitted model"="blue")) +
scale_size_manual("",values=c("Data"=0.5,"Fitted model"=0.9)) + scale_linetype_manual("",values=c("Data"=1,"Fitted model"=2)) +
labs(y="Ridership")  + geom_vline(xintercept = ridership_df[length(train.ts),1], color = "red", linetype = 2) +
annotate('text', x = as.Date("2003-01-01"), y = 2500, label = 'Forecast', color = 'black', size=5)  +
scale_x_date(breaks =  seq(as.Date("1991-01-01"), as.Date("2004-03-01"), by="2 year")) + theme_minimal()

```



## **2.2 Dynamic linear model(DLM)**

- DLM은 상태공간모형의 특별한 경우로 선형성과 정규성을 가정하고 있다. 
- DLM은 시간에 따라 변화하는 회귀계수를 가지는 선형회귀모형의 일반화 형태이다.
- DLM은 `dlm` package 안에 있는 여러 함수들을 이용하여 추정과 예측을 실시할 수 있다.

### **2.2.1 모형 적합**

```{r}
# Fit Dynamic linear model (DLM) 

model1 <- function(p){
  
               mod <- dlmModPoly(2) +  # local trend linear 
                      dlmModSeas(12)
  
  V(mod)            <- exp(p[1])
  diag(W(mod))[1:3] <- exp(p[2:4])
  
  return(mod)  
}

mle1 <- dlmMLE(train.ts, parm=c(0.1,0.1,1,1), build=model1 )   # Estimation parameter through MLE. Parameter= Variance of error
ifelse(mle1$convergence==0, print("converge"), print("did not converge") ) # Check Convergence

```


- DLM 모형의 모수는 상태와 관측값의 오차의 분산이다.
- `dlmMLE()`을 이용하여 MLE 추정량을 얻었다.
- 모수를 추정한 후  모수의 수렴성을 확인하였더니 수렴하였다.


```{r}
modelfit1 <- model1(mle1$par)  # Fitting the DLM
V(modelfit1)
W(modelfit1)
```


- $V$는 관측값의 오차의 분산이며, $W$는 상태의 오차의 공분산 행렬이다.
- $W$의 1열은 level, 2열은 slope, 3열부터 13열은 계절성과 관련되어 있다.



### **2.2.2 Kalman filtering**


- DLM에서 상태를 추정하는 방법에는 Kalman filtering 과 smoothing 방법 두 가지가 있다. 
- Kalman filtering은 과거와 현재까지 관측된 관측값으로 현재의 상태를 추정하며, smoothing은 주어진 모든 관측값을 이용하여 과거의 상태를 추정한다.
- `dlmFilter()` 함수를 이용하여 kalman filtering을 실시할 수 있다.


```{r}
# Estimation for Kalman filtering

filtering <- dlmFilter(train.ts, modelfit1)
str(filtering,1)



```


- 다음은 kalman filtering에 의해서 추정된 값과 실제 관측값에 대한 그래프이다.


```{r}

# Plot estimation for filtering model

plot(dropFirst(filtering$f), col="blue", lwd=2, lty=2, ylab="Ridership")
lines(train.ts ,lty=1, lwd=2, col="black") 
legend("bottomleft", legend=c("Data", "Fitted filtering data"), col=c("black", "blue"), lty=1:2, lwd=2)
```


- Kalman filtering에 의해 추정된 상태들에 대한 그래프이다.


```{r}

# Plot for estimated states

plot(dropFirst(filtering$m[,1]), ylab="Level")
plot(dropFirst(filtering$m[,2]), ylab="Slope")
plot(dropFirst(filtering$m[,3]), ylab="Seasonality")


```


```{r}
# Plot for data and estimated level

plot(train.ts, ylim=c(1000,2600), ylab="Ridership")
lines(dropFirst(filtering$m[,1]) ,lty=2, lwd=2, col="blue") 
legend("topright", legend=c("Data", "Filtered level"), col=c("black", "blue"), lty=1:2, lwd=1:2)
```


### **2.2.3 Kalman smoother**

- `dlmsmooth()` 함수를 이용하여 kalman smoothing을 실시할 수 있다.


```{r}
# Estimation for Kalman smoother

smoothing <- dlmSmooth(filtering)   # dlmSmooth(Filted DLM)  or dlmSmooth(train.ts, modelfit1)
str(smoothing,1)

# Plot estimation for smoothing model

theta         <- modelfit1$GG%*%t(smoothing$s[1:length(train.ts),])  #s0-s[t] : Total t+1
fitted_smooth <- modelfit1$FF%*%theta


plot(train.ts, ylab="Ridership", lwd=2)
time <- as.vector(time(train.ts))
lines(time, fitted_smooth ,lty=2, lwd=2, col="blue") 
legend("bottomleft", legend=c("Data", "Fitted smoothing data"), col=c("black", "blue"), lty=1:2, lwd=2)


# Plot for estimated states

 
plot(dropFirst(smoothing$s[,1]), ylab="Level")
plot(dropFirst(smoothing$s[,2]), ylab="Slope")
plot(dropFirst(smoothing$s[,3]), ylab="Seasonality")

# Plot for data and estimated level


plot(train.ts, ylim=c(1000,2600), ylab="Ridership")
lines(dropFirst(smoothing$s[,1]) ,lty=2, lwd=2, col="blue") 
legend("topright", legend=c("Data", "Smoothed level"), col=c("black", "blue"), lty=1:2, lwd=1:2)

```


- DLM은 정규분포를 가정하기 때문에 마지막에 오차에 대한 정규성과 독립성 확인이 필요하다.
- 아래의 그래프를 보면 오차가 평균이 0인 정규분포를 따르며 독립임을 볼 수 있다.


```{r}

# Residual(Check independence and normality)


plot(residuals(filtering,sd = FALSE), ylab="Residual")
abline(h=0)
tsdiag(filtering, main = "Diagnostics for Regression Model")


# Check normality for error

qqnorm(residuals(filtering, sd = FALSE))
qqline(residuals(filtering, sd = FALSE))

```


### **2.2.4 예측**

- `dlmForecast()` 함수를 이용하여 kalman smoothing을 실시할 수 있다.


```{r}
# Forecast
  
forecast_DLM <- dlmForecast(filtering, nAhead = nValid)  # Forecast(filtering model)
str(forecast_DLM,1)
        
               
```

### **2.2.5 그래프**

```{r}
# Plot for DLM 

DLM      <- ridership_df %>% mutate("Fitted"=c(filtering$f,forecast_DLM$f))  # Combine original data and fitted data
 
lower_DLM <- c(rep(0,length(train.ts)), forecast_DLM$f - qnorm(0.975)*sqrt(unlist(forecast_DLM$Q)))  # Lower of 95% confidence interval
upper_DLM <- c(rep(0,length(train.ts)), forecast_DLM$f + qnorm(0.975)*sqrt(unlist(forecast_DLM$Q)))  # Upper of 95% confidence interval
    

ggplot(data=DLM, aes(x=Date, y=Observation)) + geom_line(aes(color="Data", size="Data", linetype="Data")) + 
geom_line(aes(x=Date, y=Fitted, colour="Fitted model", size="Fitted model", linetype="Fitted model")) + 
scale_color_manual(name="",values=c("Data"="black", "Fitted model"="blue")) +
scale_size_manual("",values=c("Data"=0.5,"Fitted model"=0.9)) + scale_linetype_manual("",values=c("Data"=1,"Fitted model"=2)) +
labs(y="Ridership")  + geom_vline(xintercept = ridership_df[length(train.ts),1], color = "red", linetype = 2) +
annotate('text', x = as.Date("2003-01-01"), y = 2700, label = 'Forecast', color = 'black', size=5)  +
scale_x_date(breaks =  seq(as.Date("1991-01-01"), as.Date("2004-03-01"), by="2 year")) + theme_minimal() +
geom_ribbon(aes(ymin=lower_DLM, ymax=upper_DLM), fill="#99CCFF", alpha=0.5)
```


## **2.3 Bootstrap and Bagging**

- 시계열은 의존성 data이기에 `bld.mbb.bootstrap()`을 이용하여 blocked bootstrap을 실시할 수 있다.
- 붓스트랩과 Bagging 방법의 가장 큰 핵심은 예측구간을 만들 수 있다는 것과 bagging을 이용하여 점 예측을 향상시킬 수 있다는 것이다.

### **2.3.1 모형 적합과 예측**


- 1000세트의 bootstrapped 시계열을 ARIMA 모형으로 변형 후 예측을 실시하였다.


```{r}
set.seed(10)
bagged          <- train.ts %>% baggedModel(bld.mbb.bootstrap(train.ts,1000),fn=auto.arima) 
forecast_bagged <- bagged %>% forecast(h=nValid)  # Auto.arima is more accurate than ets. / After generating bootstrapped time series, convert auto.arima. Then forecast. 

```


- 붓스트랩 시계열의 예측은 100% 신뢰구간만 나타내기에 붓스트랩 시계열의 점 예측값들을 이용하여 직접 구해야한다.


```{r}
# 95% confidence interval
 
boot.pred  <- forecast_bagged$forecasts_boot
CI.boot    <- apply(boot.pred, 1, function(x) { quantile(x, probs = c(0.025, 0.975) ) }) %>% t() # Forecast confidence interval of Validation data 
CI.pred    <- rbind(matrix(rep(0,length(train.ts)*2), nrow=length(train.ts)), CI.boot)
lower_boot <- CI.pred[,1]
upper_boot <- CI.pred[,2]
```


### **2.3.2 그래프**

```{r}

boots <- ridership_df %>% 
  mutate("Fitted"=c(bagged$fitted,forecast_bagged$mean)) # Combine original data and fitted data
        
```

```{r}
ggplot(data=boots, aes(x=Date, y=Observation)) + geom_line(aes(color="Data", size="Data", linetype="Data")) + 
geom_line(aes(x=Date, y=Fitted, colour="Fitted model", size="Fitted model", linetype="Fitted model")) + 
scale_color_manual(name="",values=c("Data"="black", "Fitted model"="blue")) +
scale_size_manual("",values=c("Data"=0.5,"Fitted model"=0.9)) + scale_linetype_manual("",values=c("Data"=1,"Fitted model"=2)) +
labs(y="Ridership")  + geom_vline(xintercept = ridership_df[length(train.ts),1], color = "red", linetype = 2) +
annotate('text', x = as.Date("2003-01-01"), y = 2700, label = 'Forecast', color = 'black', size=5)  +
scale_x_date(breaks =  seq(as.Date("1991-01-01"), as.Date("2004-03-01"), by="2 year")) + theme_minimal() +
geom_ribbon(aes(ymin=lower_boot, ymax=upper_boot), fill="#99CCFF", alpha=0.5)        
 
```

## **2.4 Neural network**

### **2.4.1 모형 적합과 예측**

```{r}
set.seed(10)
neural_model <- nnetar(train.ts,  repeats=200, lambda="auto") 
forecast_neu <- forecast(neural_model, PI=TRUE, npaths=1000, h=nValid, level=95) # Npaths : How many simulation/ Normal error 

# 95% confidence interval
           
lower_neu <- c(rep(0,length(train.ts)), forecast_neu$lower)
upper_neu <- c(rep(0,length(train.ts)), forecast_neu$upper)

```


### **2.4.2 그래프**

```{r}
neu <- ridership_df %>% mutate("Fitted"=c(neural_model$fitted, forecast_neu$mean)) 

```

```{r}
ggplot(data=neu, aes(x=Date, y=Observation)) + geom_line(aes(color="Data", size="Data", linetype="Data")) + 
geom_line(aes(x=Date, y=Fitted, colour="Fitted model", size="Fitted model", linetype="Fitted model")) + 
scale_color_manual(name="",values=c("Data"="black", "Fitted model"="blue")) +
scale_size_manual("",values=c("Data"=0.5,"Fitted model"=0.9)) + scale_linetype_manual("",values=c("Data"=1,"Fitted model"=2)) +
labs(y="Ridership")  + geom_vline(xintercept = ridership_df[length(train.ts),1], color = "red", linetype = 2) +
annotate('text', x = as.Date("2003-01-01"), y = 2700, label = 'Forecast', color = 'black', size=5)  +
scale_x_date(breaks =  seq(as.Date("1991-01-01"), as.Date("2004-03-01"), by="2 year")) + theme_minimal() +
geom_ribbon(aes(ymin=lower_neu, ymax=upper_neu), fill="#99CCFF", alpha=0.5)
  
```


# **3. 모형 비교**

## **3.1 그래프**

```{r}
 df <- rbind(
   
    data.frame(Date=ridership_df[-1,1], y=ridership_df[-1,2], series="Original", ymin=0, ymax=0),
    data.frame(Date=ridership_df[-1,1], y=c(dropFirst(train.lm.trend.season$fitted),Improved_forecast), series="Regression", ymin=0, ymax=0),
    data.frame(Date=ridership_df[-1,1], y=c(dropFirst(filtering$f), forecast_DLM$f), series="DLM(Filtering)", ymin=dropFirst(lower_DLM), ymax=dropFirst(upper_DLM)),
    data.frame(Date=ridership_df[-1,1], y=c(dropFirst(bagged$fitted),forecast_bagged$mean), series="Bootstrap and Bagging", ymin=dropFirst(lower_boot), ymax=dropFirst(upper_boot)),  
    data.frame(Date=ridership_df[-1,1], y=c(dropFirst(neural_model$fitted), forecast_neu$mean), series="Neutral network" , ymin=dropFirst(lower_neu), ymax=dropFirst(upper_neu))
    
  )
  
  
ggplot(df, aes(x=Date, y=y, group=series,color=series, size=series)) + geom_line() +
geom_ribbon(aes(ymin=ymin, ymax=ymax, fill=series), alpha=0.5, colour = NA, show.legend = FALSE) +
scale_color_manual("",values = c("black","green", "red", "blue", "magenta")) +
scale_size_manual("",values=c(1.2,rep(1,4))) +
scale_fill_manual("",values=c("#FFFFFF","#99FF99","#FFCC99", "#0099FF", "#FF99CC")) +
labs(y="Ridership")  + geom_vline(xintercept = ridership_df[length(train.ts),1], color = "black", linetype = 2) +
annotate('text', x = as.Date("2003-01-01"), y = 2700, label = 'Forecast', color = 'black', size=5)  +
scale_x_date(breaks =  seq(as.Date("1991-01-01"), as.Date("2004-03-01"), by="2 year")) + theme_minimal() 
  
  

```

## **3.2 결과값**

### **3.2.1 적합된 값의 MSE**

```{r}
# Fit model 
  
filtering$f[1]      <- NA  # First value changes to NA
                
point_fitted_result <- ridership_df[1:length(train.ts),] %>% mutate("Regression"=c(train.lm.trend.season$fitted)) %>% 
                                  mutate("DLM(Filtering)"=filtering$f) %>% mutate("Bootstrap and Bagging"=bagged$fitted) %>% 
                                  mutate("Neural network"=neural_model$fitted)
point_fitted_result
           
apply(point_fitted_result[,3:6], 2, function(x){ mean((x-train.ts)^2, na.rm=TRUE) } )  # MSE
                 
```

### **3.2.2 예측값의 MSE**

```{r}
# Forecast model
  
point_forecast_result <- ridership_df[-(1:length(train.ts)),] %>% mutate("Regression"=Improved_forecast) %>% 
                                 mutate("DLM"= c(forecast_DLM$f)) %>% mutate("Bootstrap and Bagging"=forecast_bagged$mean) %>%
                                 mutate("Neural network"=forecast_neu$mean)
        
point_forecast_result
 
apply(point_forecast_result[,3:6], 2, function(x){ mean((x-valid.ts)^2) } )  # MSE
```

### **3.2.3 검증용 데이터에 대한 95% 신뢰구간 길이**

```{r}
     
length_confidence_DLM  <- upper_DLM[-(1:length(train.ts))]-lower_DLM[-(1:length(train.ts))]
length_confidence_boot <- upper_boot[-(1:length(train.ts))]-lower_boot[-(1:length(train.ts))]
length_confidence_neu  <- upper_neu[-(1:length(train.ts))]-lower_neu[-(1:length(train.ts))]
 
length_confidence <- data.frame("DLM"=length_confidence_DLM, "Bootstrap and Bagging"=length_confidence_boot,"Neural network"=length_confidence_neu )
length_confidence
```


