---
title: "Ridge Regression using Package glmnet"
description: |
  Description for Ridge Regression using Package glmnet
author:
  - name: Yeongeun Jeon
  - name: Jung In Seo
date: 2023-08-05
categories: Data Mining
output: 
  distill::distill_article:
        toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(width=200)
```


```{css, echo=FALSE}

p, ul, li{
text-align: justify
}

```

> Ridge Regression의 장점
 
- 규제항을 통해 회귀계수를 "0"에 가깝게 추정한다.
    - 회귀계수 추정치의 분산을 감소시켜 `Training Dataset`의 변화에도 회귀계수 추정치가 크게 변하지 않는다.


</br>

> Ridge Regression의 단점

- $\lambda = \infty$가 아닌 한 회귀계수를 정확하게 "0"으로 추정하지 못한다.
    - 변수 선택을 수행할 수 없다.
- 예측변수가 많을 경우 해석이 어렵다.

</br>
 
 > 실습 자료 : 유니버셜 은행의 고객 2,500명에 대한 자료(출처 : Data Mining for Business Intelligence, Shmueli et al. 2010)이며, 총 13개의 변수를 포함하고 있다. 이 자료에서 **Target**은 `Personal Loan`이다.

<center>![](./image/그림1.png)</center>

<br />

<center><img src="./image/표.png" width="400" height="400"></center>

<br />

----------

# **1. 데이터 불러오기**


```{r, eval=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr",
               "ggplot2", "GGally",
               "caret",
               "glmnet")                                                # For glmnet

UB <- fread("../Universal Bank_Main.csv")                               # 데이터 불러오기

UB %>%
  as_tibble
```

```{r, echo=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr",
               "ggplot2", "GGally",
               "caret",
               "glmnet")                                               # For glmnet

UB <- fread(paste(getwd(), "Universal Bank_Main.csv", sep = "/"))      # 데이터 불러오기

UB %>%
  as_tibble
```

----------

# **2. 데이터 전처리 I**

```{r}
UB %<>%
  data.frame() %>%                                                      # Data Frame 형태로 변환 
  mutate(Personal.Loan = ifelse(Personal.Loan == 1, "yes", "no")) %>%   # Target을 문자형 변수로 변환
  select(-1)                                                            # ID 변수 제거

# Convert to Factor
fac.col <- c("Family", "Education", "Securities.Account", 
             "CD.Account", "Online", "CreditCard",
             # Target
             "Personal.Loan")

UB <- UB %>% 
  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환

glimpse(UB)                                                             # 데이터 구조 확인
```

----------

# **3. 데이터 탐색**

```{r}
ggpairs(UB,                                             
        columns = c("Age", "Experience", "Income",        # 수치형 예측 변수
                    "ZIP.Code", "CCAvg", "Mortgage"),                            
        aes(colour = Personal.Loan)) +                    # Target의 범주에 따라 색깔을 다르게 표현
  theme_bw()  

ggpairs(UB,                                               
        columns = c("Age", "Experience", "Income",        # 수치형 예측 변수
                    "ZIP.Code", "CCAvg", "Mortgage"), 
        aes(colour = Personal.Loan)) +                    # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#00798c", "#d1495b")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#00798c", "#d1495b")) +   # 특정 색깔 지정
  theme_bw()

ggpairs(UB,                                               
        columns = c("Age", "Income",                      # 수치형 예측 변수
                    "Family", "Education"),               # 범주형 예측 변수
        aes(colour = Personal.Loan, alpha = 0.8)) +       # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#E69F00", "#56B4E9")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#E69F00", "#56B4E9")) +   # 특정 색깔 지정
  theme_bw()
```

----------

# **4. 데이터 분할**

```{r}
# Partition (Training Dataset : Test Dataset = 7:3)
y      <- UB$Personal.Loan                            # Target
 
set.seed(200)
ind    <- createDataPartition(y, p = 0.7, list = T)   # Index를 이용하여 7:3으로 분할
UB.trd <- UB[ind$Resample1,]                          # Training Dataset
UB.ted <- UB[-ind$Resample1,]                         # Test Dataset
```

----------

# **5. 데이터 전처리 II**

```{r}
# 1. Standardization
preProcValues <- preProcess(UB.trd, 
                            method = c("center", "scale"))  # Training Dataset에 대한 평균과 표준편차 계산 

UB.trd <- predict(preProcValues, UB.trd)                    # 표준화 for Training Dataset
UB.ted <- predict(preProcValues, UB.ted)                    # 표준화 for Test Dataset

glimpse(UB.trd)                                             # 데이터 구조 확인
glimpse(UB.ted)                                             # 데이터 구조 확인


# 2. Convert Factor Var. into Dummy Var. 
train.x <- model.matrix(Personal.Loan ~.,                   # Personal.Loan은 Target으로 제외  
                        UB.trd)[,-1]                        # [,-1] : 절편 제거

train.x

test.x <- model.matrix(Personal.Loan ~.,                    # Personal.Loan은 Target으로 제외  
                       UB.ted)[,-1]                         # [,-1] : 절편 제거

test.x
```

----------

# **6. 모형 훈련**

Package `"glmnet"`에서 제공하는 함수 `glmnet()`을 이용하여 `Ridge Regression`을 수행할 수 있다. 함수 `glmnet()`는 Target이 2개의 클래스를 가질 때 "두 번째 클래스"에 속할 확률을 모델링하며, "두 번째 클래스"란 "Factor" 변환하였을 때 두 번째 수준(Level)을 의미한다. 예를 들어, "a"와 "b" 2개의 클래스를 가진 Target을 "Factor" 변환하였을 때 수준이 "a" "b"라면, 첫 번째 클래스는 "a", 두 번째 클래스는 "b"가 된다. 함수 `glmnet()`에 대한 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/glmnet/versions/4.1-8/topics/glmnet)를 참고한다.


```{r, eval = FALSE}
glmnet(x, y, family, alpha, lambda, ...)
```

- `x` : 예측 변수를 포함하는 행렬
- `y` : Target을 포함하는 변수
- `family` : Target의 분포
    - `"gaussian"` : 수치형인 Target
    - `"binomial"` : 2개의 클래스를 가지는 Target
    - `"multinomial"` : 3개 이상 클래스를 가지는 Target
    - `"poisson"` : Count Data인 Target
- `alpha` : Elasticnet Mixing Parameter
    - `0` : Ridge Regression
    - `1` : Lasso Regression
    - `0 < alpha < 1` : Elastic Net Regression
- `lambda` : Regularization Parameter 
    - 직접 값을 지정하면 해당 값에 대한 결과만 보여준다.
    - 값을 지정하지 않으면 100개의 `lambda` 값에 대한 결과를 보여준다.
    
-------------

## **6-1. 람다 값 직접 지정**

```{r}
ridge.fit <- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬
                    y = UB.trd$Personal.Loan,    # Target
                    family = "binomial",         # Binary Classification
                    alpha = 0,                   # 0 : Ridge / 1 : Lasso / 0 < alpha < 1 : Elastic Net
                    lambda = 1)

round(coef(ridge.fit), 3)                        # 회귀계수 추정치
```

`Result!` 데이터 "UB.trd"의 Target "Personal.Loan"은 "no"와 "yes" 2개의 클래스를 가지며, "Factor" 변환하면 알파벳순으로 수준을 부여하기 때문에 "yes"가 두 번째 클래스가 된다. 즉, "yes"에 속할 확률(= 개인 대출 제의를 수락할 확률)을 $p$라고 할 때, 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다.
$$
\begin{align*}
\log{\frac{p}{1-p}} = &-2.265 -0.004 Z_{\text{Age}} -0.004 Z_{\text{Experience}} + 0.138 Z_{\text{Income}} \\
                      &+0.002 Z_{\text{ZIP.Code}} -0.040 X_{\text{Family2}} + 0.046 X_{\text{Family3}} +  0.030 X_{\text{Family4}}   \\
                      &+ 0.093 Z_{\text{CCAvg}} + 0.058 X_{\text{Education2}} + 0.058 X_{\text{Education3}} + 0.038 Z_{\text{Mortgage}} \\
                      &+ 0.019 X_{\text{Securities.Account1}} + 0.380 X_{\text{CD.Account1}} +  0.016 X_{\text{Online1}} -0.014 X_{\text{CreditCard1}}
\end{align*}
$$
여기서, $Z_{\text{예측 변수}}$는 표준화한 예측 변수, $X_{\text{예측 변수}}$는 더미 변수를 의미한다.


-------------

## **6-2. 교차 검증을 통한 최적의 람다 값**

```{r}
# 100개의 람다 값에 따른 결과
ridge.fit <- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬
                    y = UB.trd$Personal.Loan,    # Target
                    family = "binomial",         # Binary Classification
                    alpha = 0)                   # 0 : Ridge / 1 : Lasso / 0 < alpha < 1 : Elastic Net

plot(ridge.fit, xvar = "lambda")                 # 람다 값에 따른 회귀계수 추정치 확인
```

`Result!` 100개의 $\lambda$ 값에 대한 회귀계수 추정치의 변화를 보여준다. 해당 그림을 통해 $\lambda$ 값이 클수록 회귀계수 추정치는 작아진다는 것을 알 수 있다.

```{r}
ridge.fit$lambda                                 # 100개의 람다 값
coef(ridge.fit)                                  # 100개의 람다 값에 따른 회귀계수 추정치
coef(ridge.fit)[,100]                            # 100번째 람다 값에 대한 회귀계수 추정치
```

-------------

`Caution!` $\lambda$는 모형이 `Training Dataset`에 과적합 되는 것을 방지하기 위해 사용하는 모수이며, 교차 검증(Cross Validation)을 통해 최적의 값을 찾을 수 있다. 이러한 방법은 package `"glmnet"`에서 제공하는 함수 `cv.glmnet()`을 통해 수행할 수 있으며, 함수에 대한 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/glmnet/versions/4.1-8/topics/cv.glmnet)를 참고한다.

```{r}
set.seed(200)                                          # Seed 고정 -> 동일한 결과를 출력하기 위해
cv.ridge.fit <- cv.glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬
                          y = UB.trd$Personal.Loan,    # Target
                          family = "binomial",         # Binary Classification
                          alpha = 0,                   # 0 : Ridge / 1 : Lasso / 0 < alpha < 1 : Elastic Net
                          nfolds = 5,                  # 5-Fold Cross Validation
                          type.measure = "auc")        # AUC에 기반하여 최적의 람다 값 찾기
plot(cv.ridge.fit)                                     # Plot
```

`Result!` 100개의 $\lambda$ 값에 대한 AUC의 변화를 보여준다.  
`Caution!` 만약 $\lambda$ 값에 대해 직접 후보 값을 지정하고 싶으면 함수 `cv.glmnet()`의 옵션 `lambda = 후보 값`을 이용하면 된다.

```{r}
cv.ridge.fit$lambda.min                                   # 최적의 람다 값
max(cv.ridge.fit$cvm)                                     # 최적의 람다 값에 대한 AUC
round(coef(cv.ridge.fit, s = cv.ridge.fit$lambda.min), 3) # 최적의 람다 값에 대한 회귀계수 추정치
```

`Result!` 최적의 $\lambda$ 값에 대해 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다.
$$
\begin{align*}
\log{\frac{p}{1-p}} = &-4.081 + 0.019 Z_{\text{Age}} + 0.011 Z_{\text{Experience}} + 1.286 Z_{\text{Income}} \\
                      &+0.069 Z_{\text{ZIP.Code}}-0.388 X_{\text{Family2}} + 0.820 X_{\text{Family3}} +  0.715 X_{\text{Family4}}   \\
                      &+ 0.372 Z_{\text{CCAvg}} + 1.300 X_{\text{Education2}} + 1.277 X_{\text{Education3}} + 0.090 Z_{\text{Mortgage}} \\
                      &-0.487 X_{\text{Securities.Account1}} + 2.403 X_{\text{CD.Account1}} -0.102 X_{\text{Online1}} -0.584 X_{\text{CreditCard1}}
\end{align*}
$$

---------------

# **7. 모형 평가**

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률` 이 필요하며, 함수 `predict()`를 이용하여 생성한다. 
```{r}
# 예측 class 생성
test.ridge.class <- predict(cv.ridge.fit, 
                            newx = test.x,             # Test Dataset including Only 예측 변수 
                            s = "lambda.min",          # 최적의 람다 값 기반
                            type = "class")            # 예측 class 생성


test.ridge.class %>%                                      
  as_tibble
```

<br />

## **7-1. ConfusionMatrix**

```{r}
CM   <- caret::confusionMatrix(as.factor(test.ridge.class), UB.ted$Personal.Loan, 
                               positive = "yes")       # confusionMatrix(예측 class, 실제 class, positive = "관심 class")
CM
```

<br />

## **7-2. ROC 곡선**

```{r}
# 예측 확률 생성
test.ridge.prob <- predict(cv.ridge.fit, 
                           newx = test.x,              # Test Dataset including Only 예측 변수 
                           s = "lambda.min",           # 최적의 람다 값 기반
                           type = "response")          # 예측 확률 생성


test.ridge.prob %>%                                    # "Personal.Loan = yes"에 대한 예측 확률                           
  as_tibble
```

```{r}
ac  <- UB.ted$Personal.Loan                            # Test Dataset의 실제 class 
pp  <- as.numeric(test.ridge.prob)                     # 예측 확률을 수치형으로 변환
```

### **1) Package "pROC"**

```{r}
pacman::p_load("pROC")

ridge.roc  <- roc(ac, pp, plot = T, col = "gray")      # roc(실제 class, 예측 확률)
auc        <- round(auc(ridge.roc), 3)
legend("bottomright", legend = auc, bty = "n")

```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(ridge.roc,   
         col="gray",                                   # Line Color
         print.auc = TRUE,                             # AUC 출력 여부
         print.auc.col = "red",                        # AUC 글씨 색깔
         print.thres = TRUE,                           # Cutoff Value 출력 여부
         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                      # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                   # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(ridge.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```



### **2) Package "Epi"**

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                              # ROC(예측 확률, 실제 class)  

```

### **3) Package "ROCR"**

```{r}
pacman::p_load("ROCR")

ridge.pred <- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) 

ridge.perf <- performance(ridge.pred, "tpr", "fpr")    # performance(, "민감도", "1-특이도")                      
plot(ridge.perf, col = "gray")                         # ROC Curve

perf.auc   <- performance(ridge.pred, "auc")           # AUC
auc        <- attributes(perf.auc)$y.values
legend("bottomright", legend = auc, bty = "n")
```

<br />

## **7-3. 향상 차트**

### **1) Package "ROCR"**

```{r}
ridge.perf <- performance(ridge.pred, "lift", "rpp")   # Lift Chart                      
plot(ridge.perf, main = "lift curve",
     colorize = T,                                     # Coloring according to cutoff 
     lwd = 2) 

```


```{r, eval=F, echo=F, include=FALSE}
#### **2) Package "lift"**

pacman::p_load("lift")

plotLift(test.ridge.prob, UB.ted$Personal.Loan, cumulative = T, n.buckets = 24) # plotLift(7-2에서 생성한 예측 확률, 실제 class)
TopDecileLift(test.ridge.prob, UB.ted$Personal.Loan)		                        # Top 10%의 향상도 출력

```
