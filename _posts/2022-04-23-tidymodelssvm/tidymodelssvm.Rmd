---
title: "Support Vector Machine based on Tidymodels"
description: |
  R code using Tidymodels Package for Support Vector Machine
author:
  - name: Yeongeun Jeon
  - name: Jung In Seo
date: 04-23-2022
preview: preview.PNG
categories: Machine Learning
output: 
  distill::distill_article:
        toc: TRUE
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=200)
```


```{css, echo=FALSE}

p, ul, li{
text-align: justify
}

```



> Package `tidymodels (Ver 0.2.0)`는 R에서 머신러닝(Machine Learning)을 `tidyverse principle`로 수행할 수 있게끔 해주는 패키지 묶음이다. 특히, 모델링에 필요한 필수 패키지들을 대부분 포함하고 있기 때문에 데이터 전처리부터  시각화, 모델링, 예측까지 모든 과정을 `tidy framework`로 진행할 수 있다. 또한, Package `caret`을 완벽하게 대체하며 보다 더 빠르고 직관적인 코드로 모델링을 수행할 수 있다. 
Package `tidymodels`를 이용하여 `Support Vector Machine`을 수행하는 방법을 설명하기 위해 "Heart Disease Prediction" 데이터를 예제로 사용한다. 이 데이터는 환자의 심장병을 예측하기 위해 총 918명의 환자에 대한 10개의 예측변수로 이루어진 데이터이다(출처 : Package MLDataR, Gary Hutson 2021). 여기서 **Target**은 `HeartDisease`이다.

<center>
  ![](image/그림1.png){width=85%}
</center>

<br />

<center>
  ![](image/표.png){width=70%}
</center>

----------

# **0. Schematic Diagram**

<center>
  ![](image/diagram.jpg){width=55%}
</center>

-----------

# **1. 데이터 불러오기**

```{r}
# install.packages("tidymodels")
pacman::p_load("MLDataR",                                              # For Data
               "data.table", "magrittr",
               "tidymodels",
               "doParallel", "parallel")

registerDoParallel(cores=detectCores())


data(heartdisease)
data <- heartdisease %>%
  mutate(HeartDisease = ifelse(HeartDisease==0, "no", "yes"))


cols <- c("Sex", "RestingECG", "Angina", "HeartDisease")

data   <- data %>% 
  mutate_at(cols, as.factor)                                           # 범주형 변수 변환

glimpse(data)                                                          # 데이터 구조 
```

-----------

# **2. 데이터 분할**

```{r}
set.seed(100)                                                          # seed 고정
data.split <- initial_split(data, prop = 0.7, strata = HeartDisease)   # Partition (Traning Data : Test Data = 7:3)/ initial_split(, strata = 층화추출할 변수)
HD.train   <- training(data.split)
HD.test    <- testing(data.split)
```

-----------

# **3. Linear Kernel**

## **3-1. 전처리 정의**

- `Workflow`를 이용하기 위해 먼저 전처리를 정의한다.

```{r}
rec  <- recipe(HeartDisease ~ ., data = HD.train) %>%                  # recipe(formula, data)
  step_normalize(all_numeric_predictors()) %>%                         # 모든 수치형 예측변수들을 표준화
  step_dummy(all_nominal_predictors(), one_hot = TRUE)                 # 모든 범주형 예측변수들에 대해 원-핫 인코딩 더미변수 생성
```

-----------

## **3-2. 모형 정의**

- 모형을 구축하기 위해 모형을 먼저 정의한다.
    - 모형을 정의하기 위해 `모형 타입(Type)`과 `모형 종류(set_mode)` 그리고 `사용할 패키지(set_engine)`가 필요하다. 
        - 모형 타입 : 사용하고자하는 머신러닝 함수 정의    
            - Linear Kernel은 함수 `svm_linear()`를 사용한다.
        - 모형 종류 : Target 유형 정의 
            - 분류(Classification) 또는 회귀(Regresssion) 중 하나를 선택한다.
        - 사용할 패키지 : 사용하고자하는 Package 정의
            - Linear Kernel은 Package `kernlab`와 `LiblineaR`를 사용할 수 있다.
- Linear Kernel의 모수에는 `cost`와 `margin`이 있다.
    - `cost` : 데이터를 잘못 분류하는 선을 긋게 될 경우 지불해야 할 cost
    - `margin` : SVM insensitive loss function의 epsilon (Only for Regression) 
- 튜닝하고 싶은 모수는 함수 `tune()`으로 지정한다.

```{r}
svm.li.tune.mod <- svm_linear(cost = tune()) %>%                       # cost : 데이터를 잘못 분류하는 선을 긋게 될 경우 지불해야 할 cost
  set_mode("classification") %>%                                       # Target 유형 정의(classification /  regression)
  set_engine("kernlab")                                                # 사용하고자하는 패키지 정의(kernlab /  LiblineaR) 

# 실제 패키지에 어떻게 적용되는지 확인
svm.li.tune.mod %>% 
  translate()
                  
```

`Caution!` 함수 `translate()`를 통해 위에서 정의한 "svm.li.tune.mod"가 실제로 Package `kernlab`의 함수 `ksvm()`에 어떻게 적용되는지 확인할 수 있다.

-----------

## **3-3. Workflow 정의**

- 앞에서 정의한 전처리와 모형을 이용하여 `Workflow`를 정의한다.

```{r}
svm.li.tune.wflow <- workflow() %>%                                    # Workflow 정의
  add_recipe(rec) %>%                                                  # 3-1에서 정의
  add_model(svm.li.tune.mod)                                           # 3-2에서 정의
```

-----------

## **3-4. 모수 범위 확인**

- 함수 `extract_parameter_set_dials()`를 이용하여 모수들의 정보를 확인할 수 있다.

```{r}
svm.li.param <- extract_parameter_set_dials(svm.li.tune.wflow)         
svm.li.param        
```

`Result!` `object`열에서 `nparam`은 모수값이 수치형임을 나타낸다. 또한, `cost`의 `object`열이 `nparam[+]`로 해당 모수의 범위가 명확하게 주어졌음을 의미한다.  

- 함수 `extract_parameter_dials()`를 이용하여 모수의 범위를 자세히 확인할 수 있다.

```{r}
svm.li.param %>%
  extract_parameter_dials("cost")
```

- `cost`의 범위를 수정하고 싶다면 함수 `update()`를 이용한다.

```{r, eval = FALSE}
# 범위 수정
svm.li.param %<>%
  update(cost =  cost(c(0.0001, 1000)))
```

-----------

## **3-5. 모형 적합**

### **3-5-1. Resampling 정의**

- Linear Kernel의 최적의 모수 조합을 찾기 위해 Resampling 방법으로 `K-Fold Cross-Validation`을 사용한다.

```{r}
set.seed(100)
train.fold    <- vfold_cv(HD.train, v = 5)                            
```

-----------

### **3-5-2. 최적의 모수 조합 찾기**

- 최적의 모수 조합을 찾기 위해 `Regular Grid`, `Latin Hypercube`, `Expand Grid`를 사용한다.

-----------

#### **3-5-2-1. Regular Grid**

```{r}
set.seed(100)
grid <-  svm.li.param %>%                                           
  grid_regular(levels = 2)
grid
```

`Result!` `cost`에 대해 후보 모수값 2개를 생성하였다.

```{r}
# 모형 적합
set.seed(100)
svm.li.tune.grid.fit <- svm.li.tune.wflow %>%                          # 3-3에서 정의
  tune_grid(
    train.fold,                                                        # 3-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = grid,                                                       # 3-5-2-1에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                           # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),              # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                            # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.li.tune.grid.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.li.tune.grid.fit, "roc_auc")                             # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.li.random <- svm.li.tune.grid.fit %>% 
  select_best("roc_auc")
best.svm.li.random 
```

`Result!` `cost = 0.000977`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

#### **3-5-2-2. Latin Hypercube**

```{r}
set.seed(100)
random <- svm.li.param %>%                                             
  grid_latin_hypercube(size = 5)
random
```

`Result!` 후보 모수 5개를 랜덤하게 생성하였다.

```{r}
# 모형 적합
set.seed(100)
svm.li.tune.random.fit <- svm.li.tune.wflow %>%                        # 3-3에서 정의
  tune_grid(
    train.fold,                                                        # 3-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = random,                                                     # 3-5-2-2에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                           # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),              # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                            # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.li.tune.random.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.li.tune.random.fit, "roc_auc")                            # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.li.random <- svm.li.tune.random.fit %>% 
  select_best("roc_auc")
best.svm.li.random 
```
 
`Result!` `cost = 0.0103`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

#### **3-5-2-3. Expand Grid**

- Latin Hypercube 방법에서 최적의 모수인 `cost = 0.0103`을 기준으로 다양한 후보값을 생성한다.

```{r}
egrid <- expand.grid(cost = seq(0.01, 0.011, 0.0001))
egrid
```

`Result!` 후보 모수값들의 집합이 생성되었다.

```{r}
# 모형 적합
set.seed(100)
svm.li.tune.egrid.fit <- svm.li.tune.wflow %>%                          # 3-3에서 정의
  tune_grid(
    train.fold,                                                         # 3-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = egrid,                                                       # 3-5-2-3에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                            # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),               # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                             # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.li.tune.egrid.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# Ref. https://juliasilge.com/blog/svm.lioost-tune-volleyball/
svm.li.tune.egrid.fit %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, cost) %>%
  pivot_longer(cost,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC") + 
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.li.tune.egrid.fit, "roc_auc")                                # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.li.egrid <- svm.li.tune.egrid.fit %>% 
  select_best("roc_auc")                                                   # select_best("accuracy")
best.svm.li.egrid 
```
 
`Result!` `cost = 0.0104`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

### **3-5-3. 최적의 모수 조합을 이용한 모형 적합**

- 최적의 모수 `cost = 0.0104`을 이용하여 모형을 구축한다.
- 함수 `finalize_workflow()`을 이용하여 앞에서 정의한 "workflow(svm.li.tune.wflow)"를 최적의 모수 조합을 가지는 "workflow"로 업데이트한다.

```{r}
# Workflow에 최적의 모수값 업데이트
final.svm.li.wflow <- svm.li.tune.wflow %>%                               # 3-3에서 정의
  finalize_workflow(best.svm.li.egrid)                                    # finalize_workflow : 최적의 모수 조합을 가지는 workflow로 업데이트
final.svm.li.wflow
```

`Caution!` 함수 `last_fit()`은 최적의 모수 조합에 대해 Training Data를 이용한 모형 적합과 Test Data에 대한 예측을 한 번에 수행할 수 있지만 seed 고정이 되지 않아 Reproducibility (재생산성)가 만족되지 않는다. 따라서, 모형 적합(함수 `fit()`)과 예측(함수 `augment()`)을 각각 수행하였다.

```{r}
# 모형 적합
set.seed(100)
final.svm.li <- final.svm.li.wflow %>% 
  fit(data = HD.train)
final.svm.li
```

```{r}
# 최종 모형
final.svm.li %>% 
  extract_fit_engine()
```

-----------

## **3-6. 예측**

```{r}
svm.li.pred <- augment(final.svm.li, HD.test)  
svm.li.pred
```

-----------

## **3-7. 모형 평가**

### **3-7-1. 평가 척도**

```{r}
conf_mat(svm.li.pred, truth = HeartDisease, estimate = .pred_class)    # truth : 실제 클래스,  estimate : 예측 클래스
conf_mat(svm.li.pred, truth = HeartDisease, estimate = .pred_class) %>%
  autoplot(type = "mosaic")                                            # autoplot(type = "heatmap")

classification_metrics <- metric_set(accuracy, mcc, 
                                     f_meas, kap,
                                     sens, spec, roc_auc)              # Test Data에 대한 Assessment Measure
classification_metrics(svm.li.pred, truth = HeartDisease,              # truth : 실제 클래스,  estimate : 예측 클래스
                       estimate = .pred_class,
                       .pred_yes, event_level = "second")              # For roc_auc
```

`Caution!` "ROC AUC"를 계산하기 위해서는 관심 클래스에 대한 예측 확률이 필요하다. 예제 데이터에서 관심 클래스는 "yes"이므로 "yes"에 대한 예측 확률 결과인 `.pred_yes`가 사용되었다. 또한, Target인 "HeartDisease" 변수의 유형을 "Factor" 변환하면 알파벳순으로 클래스를 부여하기 때문에 관심 클래스 "yes"가 두 번째 클래스가 된다. 따라서 옵션 `event_level = "second"`을 사용하여 관심 클래스가 "yes"임을 명시해주어야 한다.   

-----------

### **3-7-2. 그래프**

`Caution!` 함수 "roc_curve(), gain_curve(), lift_curve(), pr_curve()"에서는 첫번째 클래스(Level)를 관심 클래스로 인식한다. R에서는 함수 `Factor()`를 이용하여 변수 유형을 변환하면 알파벳순(영어) 또는 오름차순(숫자)으로 클래스를 부여하므로 "HeartDisease" 변수의 경우 "no"가 첫번째 클래스가 되고 "yes"가 두번째 클래스가 된다. 따라서, 예제 데이터에서 관심 클래스는 "yes"이기 때문에 옵션 `event_level = "second"`을 사용하여 관심 클래스가 "yes"임을 명시해주어야 한다.

#### **3-7-2-1. ROC Curve**

```{r}
svm.li.pred %>% 
  roc_curve(truth = HeartDisease, .pred_yes,                           # truth : 실제 클래스,  관심 클래스 예측 확률
            event_level = "second") %>%                                
  autoplot()
```

-----------

#### **3-7-2-2. Gain Curve**

```{r}
svm.li.pred %>% 
  gain_curve(truth = HeartDisease, .pred_yes,                          # truth : 실제 클래스,  관심 클래스 예측 확률 
             event_level = "second") %>%                               
  autoplot()
```

-----------

#### **3-7-2-3. Lift Curve**

```{r}
svm.li.pred %>% 
  lift_curve(truth = HeartDisease, .pred_yes,                          # truth : 실제 클래스,  관심 클래스 예측 확률 
             event_level = "second") %>%                               
  autoplot()
```

-----------

#### **3-7-2-4. Precision Recall Curve**

```{r}
svm.li.pred %>% 
  pr_curve(truth = HeartDisease, .pred_yes,                            # truth : 실제 클래스,  관심 클래스 예측 확률 
           event_level = "second") %>%                                 
  autoplot()
```

-----------

# **4. Polynomial Kernel**

## **4-1. 전처리 정의**

- `Workflow`를 이용하기 위해 먼저 전처리를 정의한다.

```{r}
rec  <- recipe(HeartDisease ~ ., data = HD.train) %>%                  # recipe(formula, data)
  step_normalize(all_numeric_predictors()) %>%                         # 모든 수치형 예측변수들을 표준화
  step_dummy(all_nominal_predictors(), one_hot = TRUE)                 # 모든 범주형 예측변수들에 대해 원-핫 인코딩 더미변수 생성
```

-----------

## **4-2. 모형 정의**

- 모형을 구축하기 위해 모형을 먼저 정의한다.
    - 모형을 정의하기 위해 `모형 타입(Type)`과 `모형 종류(set_mode)` 그리고 `사용할 패키지(set_engine)`가 필요하다. 
        - 모형 타입 : 사용하고자하는 머신러닝 함수 정의 
            - Polynomial Kernel은 함수 `svm_poly()`를 사용한다.
        - 모형 종류 : Target 유형 정의 
            - 분류(Classification) 또는 회귀(Regresssion) 중 하나를 선택한다.
        - 사용할 패키지 : 사용하고자하는 Package 정의
            - Polynomial Kernel은 Package `kernlab`를 사용할 수 있다.
- Polynomial Kernel의 모수에는 `cost`, `margin`, `degree`, `scale_factor`가 있다.
    - `cost` : 데이터를 잘못 분류하는 선을 긋게 될 경우 지불해야 할 cost
    - `margin` : SVM insensitive loss function의 epsilon (Only for Regression) 
    - `degree` : Polynimial Degree
    - `scale_factor` : Polynomial Scaling Factor
- 튜닝하고 싶은 모수는 함수 `tune()`으로 지정한다.


```{r}
svm.po.tune.mod <- svm_poly(cost         = tune(),                         # cost : 데이터를 잘못 분류하는 선을 긋게 될 경우 지불해야 할 cost
                            degree       = tune(),                         # degree : Polynomial Degree
                            scale_factor = tune()) %>%                     # scale_factor : Polynomial Scaling Factor
  set_mode("classification") %>%                                           # Target 유형 정의(classification /  regression)
  set_engine("kernlab")                                                    # 사용하고자하는 패키지 정의

# 실제 패키지에 어떻게 적용되는지 확인
svm.po.tune.mod %>% 
  translate()
```

`Caution!` 함수 `translate()`를 통해 위에서 정의한 "svm.po.tune.mod"가 실제로 Package `kernlab`의 함수 `ksvm()`에 어떻게 적용되는지 확인할 수 있다.

-----------

## **4-3. Workflow 정의**

- 앞에서 정의한 전처리와 모형을 이용하여 `Workflow`를 정의한다.

```{r}
svm.po.tune.wflow <- workflow() %>%                                        # Workflow 이용
  add_recipe(rec) %>%                                                      # 4-1에서 정의
  add_model(svm.po.tune.mod)                                               # 4-2에서 정의
  
```

-----------

## **4-4. 모수 범위 확인**

- 함수 `extract_parameter_set_dials()`를 이용하여 모수들의 정보를 확인할 수 있다.

```{r}
# 모수의 범위 확인
svm.po.param <- extract_parameter_set_dials(svm.po.tune.wflow)             
svm.po.param          
```

`Result!` `object`열에서 `nparam`은 모수값이 수치형임을 나타낸다. 또한, 모든 모수에 대해 `object`열이 `nparam[+]`로 해당 모수의 범위가 명확하게 주어졌음을 의미한다.  

- 함수 `extract_parameter_dials()`를 이용하여 모수의 범위를 자세히 확인할 수 있다.

```{r}
svm.po.param %>%
  extract_parameter_dials("degree")
```

- 만약, 특정 모수의 범위를 수정하고 싶다면 함수 `update()`를 이용한다.

```{r, eval = FALSE}
# 범위 수정
svm.po.param %<>%
  update(degree =  degree(c(1, 1000)))
```

-----------

## **4-5. 모형 적합**

### **4-5-1. Resampling 정의**

- Polynimoal Kernel의 최적의 모수 조합을 찾기 위해 Resampling 방법으로 `K-Fold Cross-Validation`을 사용한다.

```{r}
set.seed(100)
train.fold    <- vfold_cv(HD.train, v = 5)                            
```

-----------

### **4-5-2. 최적의 모수 조합 찾기**

- 최적의 모수 조합을 찾기 위해 `Regular Grid`, `Latin Hypercube`, `Expand Grid`를 사용한다.

-----------

#### **4-5-2-1. Regular Grid**

```{r}
set.seed(100)
grid <-  svm.po.param %>%                                                  
  grid_regular(levels = 2)
grid
```

`Result!` 각 모수별로 2개씩 후보값을 두어 총 8(2 $\times$ 2 $\times$ 2)개의 후보 모수 조합을 생성하였다. 

```{r}
# 모형 적합
set.seed(100)
svm.po.tune.grid.fit <- svm.po.tune.wflow %>%                              # 4-3에서 정의
  tune_grid(
    train.fold,                                                            # 4-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = grid,                                                           # 4-5-2-1에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                               # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),                  # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                                # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.po.tune.grid.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.po.tune.grid.fit, "roc_auc")                                 # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.po.grid <- svm.po.tune.grid.fit %>% 
  select_best("roc_auc")
best.svm.po.grid 
```

`Result!` `cost = 0.000977`, `degree = 3`, `scale_factor = 0.1`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

#### **4-5-2-2. Latin Hypercube**

```{r}
set.seed(100)
random <- svm.po.param %>%                                                 
  grid_latin_hypercube(size = 10)
random
```

`Result!` 10개의 후보 모수 조합을 랜덤하게 생성하였다. 

```{r}
# 모형 적합
set.seed(100)
svm.po.tune.random.fit <- svm.po.tune.wflow %>%                             # 4-3에서 정의
  tune_grid(
    train.fold,                                                             # 4-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = random,                                                          # 4-5-2-2에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                                # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),                   # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                                 # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.po.tune.random.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.po.tune.random.fit, "roc_auc")                                # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.po.random <- svm.po.tune.random.fit %>% 
  select_best("roc_auc")
best.svm.po.random 
```

`Result!` `cost = 0.00112`, `degree = 2`, `scale_factor = 0.0147`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

#### **4-5-2-3. Expand Grid**

- Latin Hypercube 방법에서 최적의 모수 조합인 `cost = 0.00112`, `degree = 2`, `scale_factor = 0.0147`을 기준으로 다양한 후보값을 생성한다.

```{r}
egrid <- expand.grid(cost         = seq(0.00112, 0.0012, 0.00001),
                     degree       = 1:3,
                     scale_factor = 0.0147)
egrid
```

`Result!` 후보 모수값들의 집합이 생성되었다.

```{r}
# 모형 적합
set.seed(100)
svm.po.tune.egrid.fit <- svm.po.tune.wflow %>%                              # 4-3에서 정의
  tune_grid(
    train.fold,                                                             # 4-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = egrid,                                                           # 4-5-2-3에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                                # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),                   # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                                 # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.po.tune.egrid.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# Ref. https://juliasilge.com/blog/svm.pooost-tune-volleyball/
svm.po.tune.egrid.fit %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, cost:scale_factor) %>%
  pivot_longer(cost:scale_factor,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.po.tune.egrid.fit, "roc_auc")                                   # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.po.egrid <- svm.po.tune.egrid.fit %>% 
  select_best("roc_auc")                                                      # select_best("accuracy")
best.svm.po.egrid 
```

`Result!` `cost = 0.00112`, `degree = 3`, `scale_factor = 0.0147`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

### **4-5-3. 최적의 모수 조합을 이용한 모형 적합**

- 최적의 모수 조합 `cost = 0.00112`, `degree = 3`, `scale_factor = 0.0147`을 이용하여 모형을 구축한다.
- 함수 `finalize_workflow()`을 이용하여 앞에서 정의한 "workflow(svm.po.tune.wflow)"를 최적의 모수 조합을 가지는 "workflow"로 업데이트한다.

```{r}
# Workflow에 최적의 모수값 업데이트
final.svm.po.wflow <- svm.po.tune.wflow %>%                                    # 4-3에서 정의
  finalize_workflow(best.svm.po.egrid)                                         # finalize_workflow : 최적의 모수 조합을 가지는 workflow로 업데이트
final.svm.po.wflow
```

`Caution!` 함수 `last_fit()`은 최적의 모수 조합에 대해 Training Data를 이용한 모형 적합과 Test Data에 대한 예측을 한 번에 수행할 수 있지만 seed 고정이 되지 않아 Reproducibility (재생산성)가 만족되지 않는다. 따라서, 모형 적합(함수 `fit()`)과 예측(함수 `augment()`)을 각각 수행하였다.

```{r}
# 모형 적합
set.seed(100)
final.svm.po <- final.svm.po.wflow %>% 
  fit(data = HD.train)
final.svm.po
```

```{r}
# 최종 모형
final.svm.po %>% 
  extract_fit_engine()
```

-----------

## **4-6. 예측**

```{r}
svm.po.pred <- augment(final.svm.po, HD.test)  
svm.po.pred
```

-----------

## **4-7. 모형 평가**

### **4-7-1. 평가 척도**


```{r}
conf_mat(svm.po.pred, truth = HeartDisease, estimate = .pred_class)    # truth : 실제 클래스,  estimate : 예측 클래스
conf_mat(svm.po.pred, truth = HeartDisease, estimate = .pred_class) %>%
  autoplot(type = "mosaic")                                            # autoplot(type = "heatmap")

classification_metrics <- metric_set(accuracy, mcc, 
                                     f_meas, kap,
                                     sens, spec, roc_auc)              # Test Data에 대한 Assessment Measure
classification_metrics(svm.po.pred, truth = HeartDisease,              # truth : 실제 클래스,  estimate : 예측 클래스
                       estimate = .pred_class,
                       .pred_yes, event_level = "second")              # For roc_auc
```

`Caution!` "ROC AUC"를 계산하기 위해서는 관심 클래스에 대한 예측 확률이 필요하다. 예제 데이터에서 관심 클래스는 "yes"이므로 "yes"에 대한 예측 확률 결과인 `.pred_yes`가 사용되었다. 또한, Target인 "HeartDisease" 변수의 유형을 "Factor" 변환하면 알파벳순으로 클래스를 부여하기 때문에 관심 클래스 "yes"가 두 번째 클래스가 된다. 따라서 옵션 `event_level = "second"`을 사용하여 관심 클래스가 "yes"임을 명시해주어야 한다.  

-----------

### **4-7-2. 그래프**

`Caution!` 함수 "roc_curve(), gain_curve(), lift_curve(), pr_curve()"에서는 첫번째 클래스(Level)를 관심 클래스로 인식한다. R에서는 함수 `Factor()`를 이용하여 변수 유형을 변환하면 알파벳순(영어) 또는 오름차순(숫자)으로 클래스를 부여하므로 "HeartDisease" 변수의 경우 "no"가 첫번째 클래스가 되고 "yes"가 두번째 클래스가 된다. 따라서, 예제 데이터에서 관심 클래스는 "yes"이기 때문에 옵션 `event_level = "second"`을 사용하여 관심 클래스가 "yes"임을 명시해주어야 한다.

#### **4-7-2-1. ROC Curve**

```{r}
svm.po.pred %>% 
  roc_curve(truth = HeartDisease, .pred_yes,                           # truth : 실제 클래스,  관심 클래스 예측 확률
            event_level = "second") %>%                                 
  autoplot()
```

-----------

#### **4-7-2-2. Gain Curve**

```{r}
svm.po.pred %>% 
  gain_curve(truth = HeartDisease, .pred_yes,                          # truth : 실제 클래스,  관심 클래스 예측 확률
             event_level = "second") %>%                              
  autoplot()
```

-----------

#### **4-7-2-3. Lift Curve**

```{r}
svm.po.pred %>% 
  lift_curve(truth = HeartDisease, .pred_yes,                          # truth : 실제 클래스,  관심 클래스 예측 확률 
             event_level = "second") %>%                                
  autoplot()
```

-----------

#### **4-7-2-4. Precision Recall Curve**

```{r}
svm.po.pred %>% 
  pr_curve(truth = HeartDisease, .pred_yes,                            # truth : 실제 클래스,  관심 클래스 예측 확률
           event_level = "second") %>%                                 
  autoplot()
```

-----------

# **5. Radial Basis Kernel**

## **5-1. 전처리 정의**

- `Workflow`를 이용하기 위해 먼저 전처리를 정의한다.

```{r}
rec  <- recipe(HeartDisease ~ ., data = HD.train) %>%                  # recipe(formula, data)
  step_normalize(all_numeric_predictors()) %>%                         # 모든 수치형 예측변수들을 표준화
  step_dummy(all_nominal_predictors(), one_hot = TRUE)                 # 모든 범주형 예측변수들에 대해 원-핫 인코딩 더미변수 생성
```

-----------

## **5-2. 모형 정의**

- 모형을 구축하기 위해 모형을 먼저 정의한다.
    - 모형을 정의하기 위해 `모형 타입(Type)`과 `모형 종류(set_mode)` 그리고 `사용할 패키지(set_engine)`가 필요하다. 
        - 모형 타입 : 사용하고자하는 머신러닝 함수 정의 
            - Radial Basis Kernel은 함수 `svm_rbf()`를 사용한다.
        - 모형 종류 : Target 유형 정의 
            - 분류(Classification) 또는 회귀(Regresssion) 중 하나를 선택한다.
        - 사용할 패키지 : 사용하고자하는 Package 정의
            - Radial Basis Kernel은 Package `kernlab`와 `liquidSVM`를 사용할 수 있다.
- Radial Basis Kernel의 모수에는 `cost`, `margin`, `rbf_sigma`가 있다.
    - `cost` : 데이터를 잘못 분류하는 선을 긋게 될 경우 지불해야 할 cost
    - `margin` : SVM insensitive loss function의 epsilon (Only for Regression) 
    - `rbf_sigma` : Precision 모수$(\gamma = \frac{1}{2\sigma^2})$ 
- 튜닝하고 싶은 모수는 함수 `tune()`으로 지정한다.

```{r}
svm.rbf.tune.mod <- svm_rbf(cost      = tune(),                            # cost : 데이터를 잘못 분류하는 선을 긋게 될 경우 지불해야 할 cost
                            rbf_sigma = tune()) %>%                        # rbf_sigma : Precision 모수(gamma = 1/2*sigma^2)
  set_mode("classification") %>%                                           # Target 유형 정의(classification /  regression)
  set_engine("kernlab")                                                    # 사용하고자하는 패키지 정의(kernlab /  liquidSVM)

# 실제 패키지에 어떻게 적용되는지 확인
svm.rbf.tune.mod %>% 
  translate()
```

`Caution!` 함수 `translate()`를 통해 위에서 정의한 "svm.rbf.tune.mod"가 실제로 Package `kernlab`의 함수 `ksvm()`에 어떻게 적용되는지 확인할 수 있다.

-----------

## **5-3. Workflow 정의**

- 앞에서 정의한 전처리와 모형을 이용하여 `Workflow`를 정의한다.

```{r}
svm.rbf.tune.wflow <- workflow() %>%                                       # Workflow 이용
  add_recipe(rec) %>%                                                      # 5-1에서 정의
  add_model(svm.rbf.tune.mod)                                              # 5-2에서 정의
  
```

-----------

## **5-4. 모수 범위 확인**

- 함수 `extract_parameter_set_dials()`를 이용하여 모수들의 정보를 확인할 수 있다.

```{r}
svm.rbf.param <- extract_parameter_set_dials(svm.rbf.tune.wflow)           
svm.rbf.param         
```

`Result!` `object`열에서 `nparam`은 모수값이 수치형임을 나타낸다. 또한, 모든 모수에 대해 `object`열이 `nparam[+]`로 해당 모수의 범위가 명확하게 주어졌음을 의미한다.    

- 함수 `extract_parameter_dials()`를 이용하여 모수의 범위를 자세히 확인할 수 있다.

```{r}
svm.rbf.param %>%
  extract_parameter_dials("rbf_sigma")
```

- 만약, 특정 모수의 범위를 수정하고 싶다면 함수 `update()`를 이용한다.

```{r, eval = FALSE}
# 범위 수정
svm.rbf.param %<>%
  update(rbf_sigma =  rbf_sigma(c(1, 1000)))
```

-----------

## **5-5. 모형 적합**

### **5-5-1. Resampling 정의**

- Radial Basis Kernel의 최적의 모수 조합을 찾기 위해 Resampling 방법으로 `K-Fold Cross-Validation`을 사용한다.

```{r}
set.seed(100)
train.fold    <- vfold_cv(HD.train, v = 5)                            
```

-----------

### **5-5-2. 최적의 모수 조합 찾기**

- 최적의 모수 조합을 찾기 위해 `Regular Grid`, `Latin Hypercube`, `Expand Grid`를 사용한다.

-----------

#### **5-5-2-1. Regular Grid**

```{r}
set.seed(100)
grid <-  svm.rbf.param %>%                                                
  grid_regular(levels = 3)
grid
```

`Result!` 각 모수별로 3개씩 후보값을 두어 총 9(3 $\times$ 3)개의 후보 모수 조합을 생성하였다. 

```{r}
# 모형 적합
set.seed(100)
svm.rbf.tune.grid.fit <- svm.rbf.tune.wflow %>%                            # 5-3에서 정의
  tune_grid(
    train.fold,                                                            # 5-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = grid,                                                           # 5-5-2-1에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                               # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),                  # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                                # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.rbf.tune.grid.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.rbf.tune.grid.fit, "roc_auc")                                 # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.rbf.grid <- svm.rbf.tune.grid.fit %>% 
  select_best("roc_auc")
best.svm.rbf.grid 
```

`Result!` `cost = 0.177`, `rbf_sigma = 0.00001`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

#### **5-5-2-2. Latin Hypercube**

```{r}
set.seed(100)
random <- svm.rbf.param %>%                                                 
  grid_latin_hypercube(size = 10)
random
```

`Result!` 10개의 후보 모수 조합을 랜덤하게 생성하였다. 

```{r}
# 모형 적합
set.seed(100)
svm.rbf.tune.random.fit <- svm.rbf.tune.wflow %>%                           # 5-3에서 정의
  tune_grid(
    train.fold,                                                             # 5-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = random,                                                          # 5-5-2-2에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                                # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),                   # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                                 # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.rbf.tune.random.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.rbf.tune.random.fit, "roc_auc")                                # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.rbf.random <- svm.rbf.tune.random.fit %>% 
  select_best("roc_auc")
best.svm.rbf.random 
```

`Result!` `cost = 2.95`, `rbf_sigma = 0.00460`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

#### **5-5-2-3. Expand Grid**

- Latin Hypercube 방법에서 최적의 모수 조합인 `cost = 2.95`, `rbf_sigma = 0.00460`을 기준으로 다양한 후보값을 생성한다.

```{r}
egrid <- expand.grid(cost      = seq(2.94, 2.95, 0.001),
                     rbf_sigma = seq(0.0046, 0.0047, 0.0001))
egrid
```

`Result!` 후보 모수값들의 집합이 생성되었다.

```{r}
set.seed(100)
svm.rbf.tune.egrid.fit <- svm.rbf.tune.wflow %>%                            # 5-3에서 정의
  tune_grid(
    train.fold,                                                             # 5-5-1에서 정의 : Resampling -> 5-Cross-Validation
    grid = egrid,                                                           # 5-5-2-3에서 정의 : 후보 모수 집합 
    control = control_grid(save_pred = TRUE,                                # Resampling의 Assessment 결과 저장
                           parallel_over = "everything"),                   # 병렬 처리(http:://tune.tidymodels.org/reference/control_grid.html) 
    metrics = metric_set(roc_auc, accuracy)                                 # Assessment 그룹에 대한 Assessment Measure
  )

# 그래프
autoplot(svm.rbf.tune.egrid.fit) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top") +
  theme_bw()

# Ref. https://juliasilge.com/blog/svm.rbfoost-tune-volleyball/
svm.rbf.tune.egrid.fit %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, cost:rbf_sigma) %>%
  pivot_longer(cost:rbf_sigma,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC") +
  theme_bw()

# 지정된 Metric 측면에서 성능이 우수한 모형을 순서대로 확인
show_best(svm.rbf.tune.egrid.fit, "roc_auc")                                # show_best(, "accuracy")

# 최적의 모수 조합 확인
best.svm.rbf.egrid <- svm.rbf.tune.egrid.fit %>% 
  select_best("roc_auc")                                                    # select_best("accuracy")
best.svm.rbf.egrid 
```

`Result!` `cost = 2.946`, `rbf_sigma = 0.0047`일 때 "ROC AUC" 측면에서 가장 우수한 성능을 보여준다.

-----------

### **5-5-3. 최적의 모수 조합을 이용한 모형 적합**

- 최적의 모수 조합 `cost = 2.946`, `rbf_sigma = 0.0047`을 이용하여 모형을 구축한다.
- 함수 `finalize_workflow()`을 이용하여 앞에서 정의한 "workflow(svm.rbf.tune.wflow)"를 최적의 모수 조합을 가지는 "workflow"로 업데이트한다.

```{r}
# Workflow에 최적의 모수값 업데이트
final.svm.rbf.wflow <- svm.rbf.tune.wflow %>%                               # 5-3에서 정의
  finalize_workflow(best.svm.rbf.egrid)                                     # finalize_workflow : 최적의 모수 조합을 가지는 workflow로 업데이트
final.svm.rbf.wflow
```

`Caution!` 함수 `last_fit()`은 최적의 모수 조합에 대해 Training Data를 이용한 모형 적합과 Test Data에 대한 예측을 한 번에 수행할 수 있지만 seed 고정이 되지 않아 Reproducibility (재생산성)가 만족되지 않는다. 따라서, 모형 적합(함수 `fit()`)과 예측(함수 `augment()`)을 각각 수행하였다.

```{r}
# 모형 적합
set.seed(100)
final.svm.rbf <- final.svm.rbf.wflow %>% 
  fit(data = HD.train)
final.svm.rbf
```

```{r}
# 최종 모형
final.svm.rbf %>% 
  extract_fit_engine()
```



-----------

## **5-6. 예측**

```{r}
svm.rbf.pred <- augment(final.svm.rbf, HD.test)  
svm.rbf.pred
```

-----------

## **5-7. 모형 평가**

### **5-7-1. 평가 척도**


```{r}
conf_mat(svm.rbf.pred, truth = HeartDisease, estimate = .pred_class)   # truth : 실제 클래스,  estimate : 예측 클래스
conf_mat(svm.rbf.pred, truth = HeartDisease, estimate = .pred_class) %>%
  autoplot(type = "mosaic")                                            # autoplot(type = "heatmap")

classification_metrics <- metric_set(accuracy, mcc, 
                                     f_meas, kap,
                                     sens, spec, roc_auc)              # Test Data에 대한 Assessment Measure
classification_metrics(svm.rbf.pred, truth = HeartDisease,             # truth : 실제 클래스,  estimate : 예측 클래스
                       estimate = .pred_class,
                       .pred_yes, event_level = "second")              # For roc_auc
```

`Caution!` "ROC AUC"를 계산하기 위해서는 관심 클래스에 대한 예측 확률이 필요하다. 예제 데이터에서 관심 클래스는 "yes"이므로 "yes"에 대한 예측 확률 결과인 `.pred_yes`가 사용되었다. 또한, Target인 "HeartDisease" 변수의 유형을 "Factor" 변환하면 알파벳순으로 클래스를 부여하기 때문에 관심 클래스 "yes"가 두 번째 클래스가 된다. 따라서 옵션 `event_level = "second"`을 사용하여 관심 클래스가 "yes"임을 명시해주어야 한다.  

-----------

### **5-7-2. 그래프**

`Caution!` 함수 "roc_curve(), gain_curve(), lift_curve(), pr_curve()"에서는 첫번째 클래스(Level)를 관심 클래스로 인식한다. R에서는 함수 `Factor()`를 이용하여 변수 유형을 변환하면 알파벳순(영어) 또는 오름차순(숫자)으로 클래스를 부여하므로 "HeartDisease" 변수의 경우 "no"가 첫번째 클래스가 되고 "yes"가 두번째 클래스가 된다. 따라서, 예제 데이터에서 관심 클래스는 "yes"이기 때문에 옵션 `event_level = "second"`을 사용하여 관심 클래스가 "yes"임을 명시해주어야 한다.

#### **5-7-2-1. ROC Curve**

```{r}
svm.rbf.pred %>% 
  roc_curve(truth = HeartDisease, .pred_yes,                           # truth : 실제 클래스,  관심 클래스 예측 확률
            event_level = "second") %>%                               
  autoplot()
```

-----------

#### **5-7-2-2. Gain Curve**

```{r}
svm.rbf.pred %>% 
  gain_curve(truth = HeartDisease, .pred_yes,                          # truth : 실제 클래스,  관심 클래스 예측 확률 
             event_level = "second") %>%                               
  autoplot()
```

-----------

#### **5-7-2-3. Lift Curve**

```{r}
svm.rbf.pred %>% 
  lift_curve(truth = HeartDisease, .pred_yes,                          # truth : 실제 클래스,  관심 클래스 예측 확률 
             event_level = "second") %>%                               
  autoplot()
```

-----------

#### **5-7-2-4. Precision Recall Curve**

```{r}
svm.rbf.pred %>% 
  pr_curve(truth = HeartDisease, .pred_yes,                            # truth : 실제 클래스,  관심 클래스 예측 확률 
           event_level = "second") %>%                                 
  autoplot()
```


