---
title: "Support Vector Machine with Linear Kernel using Package kernlab"
description: |
  Description for Support Vector Machine with Linear Kernel using Package kernlab
author:
  - name: Yeongeun Jeon
  - name: Jung In Seo
date: 2023-04-22
categories: Data Mining
output: 
  distill::distill_article:
        toc: TRUE
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(width=200)
```


```{css, echo=FALSE}

p, ul, li{
text-align: justify
}

```


> Support Vector Machine의 장점
 
- 분류 경계가 직사각형만 가능한 의사결정나무의 단점을 해결할 수 있다.
- 복잡한 비선형 결정 경계를 학습하는데 유용하다.
- 예측 변수에 분포를 가정하지 않는다. 

<br />

> Support Vector Machine의 단점

- 초모수가 매우 많으며, 초모수에 민감하다.
    - 최적의 모형을 찾기 위해 다양한 커널과 초모수의 조합을 평가해야 한다.
- 모형 훈련이 느리다.
- 연속형 예측 변수만 가능하다.
    - 범주형 예측 변수는 더미 또는 원-핫 인코딩 변환을 수행해야 한다.
- 해석하기 어려운 복잡한 블랙박스 모형이다.
 
 <br />
 
 > 실습 자료 : 유니버셜 은행의 고객 2,500명에 대한 자료(출처 : Data Mining for Business Intelligence, Shmueli et al. 2010)이며, 총 13개의 변수를 포함하고 있다. 이 자료에서 **Target**은 `Personal Loan`이다.

<center>![](./image/그림1.png)</center>

<br />

<center><img src="./image/표.png" width="400" height="400"></center>

<br />

----------


# **1. 데이터 불러오기**

```{r, eval=F}
pacman::p_load("data.table", "dplyr",
               "caret",
               "ggplot2", "GGally",
               "kernlab")


UB <- fread("../Universal Bank_Main.csv")                               # 데이터 불러오기

UB %>%
  as_tibble
```

```{r, echo=F}
pacman::p_load("data.table", "dplyr",
               "caret",
               "ggplot2", "GGally",
               "kernlab")


UB <- fread(paste(getwd(), "Universal Bank_Main.csv", sep = "/"))      # 데이터 불러오기

UB %>%
  as_tibble
```

----------

# **2. 데이터 전처리 I**

```{r}
UB %<>%
  data.frame() %>%                                                      # Data Frame 형태로 변환 
  mutate(Personal.Loan = ifelse(Personal.Loan == 1, "yes", "no")) %>%   # Target을 문자형 변수로 변환
  select(-1)                                                            # ID 변수 제거

# 1. Convert to Factor
fac.col <- c("Family", "Education", "Securities.Account", 
             "CD.Account", "Online", "CreditCard",
             # Target
             "Personal.Loan")

UB <- UB %>% 
  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환

glimpse(UB)                                                             # 데이터 구조 확인

# 2. Convert One-hot Encoding for 범주형 예측 변수
dummies <- dummyVars(formula = ~ .,                                     # formula : ~ 예측 변수 / "." : data에 포함된 모든 변수를 의미
                     data = UB[,-9],                                    # Dataset including Only 예측 변수 -> Target 제외
                     fullRank = FALSE)                                  # fullRank = TRUE : Dummy Variable, fullRank = FALSE : One-hot Encoding

UB.Var   <- predict(dummies, newdata = UB) %>%                          # 범주형 예측 변수에 대한 One-hot Encoding 변환
  data.frame()                                                          # Data Frame 형태로 변환 

glimpse(UB.Var)                                                         # 데이터 구조 확인

# 3. Combine Target with 변환된 예측 변수
UB.df <- data.frame(Personal.Loan = UB$Personal.Loan, 
                    UB.Var)

UB.df %>%
  as_tibble

glimpse(UB.df)                                                          # 데이터 구조 확인
```

----------

# **3. 데이터 탐색**

```{r}
ggpairs(UB,                                               # In 2-1
        columns = c("Age", "Experience", "Income",        # 수치형 예측 변수
                    "ZIP.Code", "CCAvg", "Mortgage"),                            
        aes(colour = Personal.Loan)) +                    # Target의 범주에 따라 색깔을 다르게 표현
  theme_bw()  

ggpairs(UB,                                               # In 2-1
        columns = c("Age", "Experience", "Income",        # 수치형 예측 변수
                    "ZIP.Code", "CCAvg", "Mortgage"), 
        aes(colour = Personal.Loan)) +                    # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#00798c", "#d1495b")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#00798c", "#d1495b")) +   # 특정 색깔 지정
  theme_bw()

ggpairs(UB,                                               # In 2-1
        columns = c("Age", "Income",                      # 수치형 예측 변수
                    "Family", "Education"),               # 범주형 예측 변수
        aes(colour = Personal.Loan, alpha = 0.8)) +       # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#E69F00", "#56B4E9")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#E69F00", "#56B4E9")) +   # 특정 색깔 지정
  theme_bw()
```

----------


# **4. 데이터 분할**

```{r}
# Partition (Training Dataset : Test Dataset = 7:3)
y      <- UB.df$Personal.Loan                            # Target
 
set.seed(200)
ind    <- createDataPartition(y, p = 0.7, list = T)      # Index를 이용하여 7:3으로 분할
UB.trd <- UB.df[ind$Resample1,]                          # Training Dataset
UB.ted <- UB.df[-ind$Resample1,]                         # Test Dataset
```


----------

# **5. 데이터 전처리 II**

```{r}
# Standardization
preProcValues <- preProcess(UB.trd, 
                            method = c("center", "scale"))  # Standardization 정의 -> Training Dataset에 대한 평균과 표준편차 계산 

UB.trd <- predict(preProcValues, UB.trd)                    # Standardization for Training Dataset
UB.ted <- predict(preProcValues, UB.ted)                    # Standardization for Test Dataset

glimpse(UB.trd)                                             # 데이터 구조 확인
glimpse(UB.ted)                                             # 데이터 구조 확인
```

----------

# **6. 모형 훈련**

Package `"kernlab"`는 커널 기반의 기계 학습 알고리듬을 R에서 구현한 Package이며, 해당 Package를 이용하여 Support Vector Machine를 수행하면 Kernel 함수가 `Radial Basis`일 때, 최적의 `sigma (gamma)` 값을 자동으로 찾아준다는 장점이 있다. 함수 `ksvm()`을 이용하여 Support Vector Machine을 수행하며, 함수에서 사용할 수 있는 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/kernlab/versions/0.9-32/topics/ksvm)를 참고한다.

```{r, eval=FALSE}
ksvm(formula, data, kernel, C, prob.model, ...) 
```

- `formula` : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 `Target ~ 예측 변수`의 형태로 표현한다.
- `data` : `formula`에 포함하고 있는 변수들의 데이터셋(Data Frame)
-  `kernel` : Kernel 함수
    - `"vanilladot"` : Linear Kernel $k(\boldsymbol{x}, \boldsymbol{x}') = \boldsymbol{x}\boldsymbol{x}'$
    - `"polydot"` : Polynomial Kernel $k(\boldsymbol{x}, \boldsymbol{x}') = (\text{scale} * \boldsymbol{x}\boldsymbol{x}' + \text{offset})^{\text{degree}}$
    - `"rbfdot"` : Radial Basis Kernel $k(\boldsymbol{x}, \boldsymbol{x}') = \exp\left(-\sigma||\boldsymbol{x}-\boldsymbol{x}'||^2 \right)$
    - `"tanhdot"` : Hyperbolic Tangent Kernel
    - `"laplacedot"` : Laplacian Kernel
    - `"splinedot"` : Spline Kernel
- `C` : 데이터를 잘못 분류하는 선을 그을 경우 지불해야 할 cost
- `prob.model` : `Test Dataset`에 대한 `예측 확률`의 생성 여부
    - `TRUE` : 함수 `predict()`를 이용하여 `Test Dataset`에 대한 `예측 확률`을 생성할 수 있다.


```{r}
svm.model.li <- ksvm(Personal.Loan ~.,     
                    data = UB.trd,  
                    kernel = "vanilladot", 
                    C = 1,              
                    prob.model = TRUE)   

svm.model.li
```

----------

# **7. 모형 평가**

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률` 이 필요하며, 함수 `predict()`를 이용하여 생성한다. 

```{r}
# 예측 class 생성 
svm.li.pred <- predict(svm.model.li,
                       newdata = UB.ted[,-1],         # Test Dataset including Only 예측 변수   
                       type = "response")             # 예측 class 생성       

svm.li.pred %>%
  as_tibble
```

<br />

## **7-1. ConfusionMatrix**

```{r}
CM   <- caret::confusionMatrix(svm.li.pred, UB.ted$Personal.Loan, 
                               positive = "yes")      # confusionMatrix(예측 class, 실제 class, positive="관심 class")
CM
```

<br />

## **7-2. ROC 곡선**

```{r}
# 예측 확률 생성
test.svm.prob <- predict(svm.model.li, 
                         newdata = UB.ted[,-1],       # Test Dataset including Only 예측 변수  
                         type = "probabilities")      # 예측 확률 생성     

test.svm.prob %>%
  as_tibble
```

```{r}
test.svm.prob <- test.svm.prob[,2]                    # "Personal.Loan = yes"에 대한 예측 확률

ac  <- UB.ted$Personal.Loan                           # Test Dataset의 실제 class 
pp  <- as.numeric(test.svm.prob)                      # 예측 확률을 수치형으로 변환
```


### **1) Package "pROC"**

```{r}
pacman::p_load("pROC")

svm.roc  <- roc(ac, pp, plot = T, col = "gray")       # roc(실제 class, 예측 확률)
auc      <- round(auc(svm.roc), 3)
legend("bottomright", legend = auc, bty = "n")
```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(svm.roc,   
         col="gray",                                  # Line Color
         print.auc = TRUE,                            # AUC 출력 여부
         print.auc.col = "red",                       # AUC 글씨 색깔
         print.thres = TRUE,                          # Cutoff Value 출력 여부
         print.thres.pch = 19,                        # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                     # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                          # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                  # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(svm.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```



### **2) Package "Epi"**

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                             # ROC(예측 확률, 실제 class)  
```


### **3) Package "ROCR"**

```{r}
pacman::p_load("ROCR")

svm.pred <- prediction(pp, ac)                        # prediction(예측 확률, 실제 class)    

svm.perf <- performance(svm.pred, "tpr", "fpr")       # performance(, "민감도", "1-특이도")                      
plot(svm.perf, col = "gray")                          # ROC Curve

perf.auc   <- performance(svm.pred, "auc")            # AUC
auc        <- attributes(perf.auc)$y.values 
legend("bottomright", legend = auc, bty = "n")
```

<br />

## **7-3. 향상 차트**

### **1) Package "ROCR"**

```{r}
svm.perf <- performance(svm.pred, "lift", "rpp")      # Lift Chart
plot(svm.perf, main = "lift curve", 
     colorize = T,                                    # Coloring according to cutoff
     lwd = 2)  
```


```{r, echo=F, eval = F, include=FALSE}
#### **2) Package "lift"**

pacman::p_load("lift")

ac.numeric <- ifelse(UB.ted$Personal.Loan == "yes", 1, 0)             # Target을 수치형으로 변환

plotLift(test.svm.prob, ac.numeric, cumulative = T, n.buckets = 24)   # plotLift(7-2에서 생성한 예측 확률, 실제 class)
TopDecileLift(test.svm.prob, ac.numeric)		                          # Top 10%의 향상도 출력
```


