---
title: "Decision Tree using Package rpart"
description: |
  Description for Decision Tree using Package rpart
author:
  - name: Yeongeun Jeon
  - name: Jung In Seo
date: 2023-03-30
preview: preview.PNG
categories: Data Mining
output: 
  distill::distill_article:
        toc: TRUE
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(width=200)
```


```{css, echo=FALSE}

p, ul, li{
text-align: justify
}

```

 > Tree-based Algorithm
 
- 범주형 예측 변수와 연속형 예측 변수 모두 적용이 가능하다.
- 예측 변수에 대한 분포 가정이 필요없다.
- 다른 척도를 가지는 연속형 예측 변수들에 대해 별도의 변환과정 없이 적용가능하다. 
    - 표준화/정규화 수행 X

<br />

 > 실습 자료 : 유니버셜 은행의 고객 2,500명에 대한 자료(출처 : Data Mining for Business Intelligence, Shmueli et al. 2010)이며, 총 13개의 변수를 포함하고 있다. 이 자료에서 **Target**은 `Personal Loan`이다.

<center>![](./image/그림1.png)</center>

<br />

<center><img src="./image/표.png" width="400" height="400"></center>

<br />

----------

# **1. 데이터 불러오기**


```{r, eval=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr",
               "ggplot2", "GGally",
               "caret",
               "rpart",                                                 # For Decision Tree
               "rattle", "rpart.plot",                                  # For fancyRpartPlot
               "visNetwork", "sparkline")                               # For visTree

UB <- fread("../Universal Bank_Main.csv")                               # 데이터 불러오기

UB %>%
  as_tibble
```

```{r, echo=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr",
               "ggplot2", "GGally",
               "caret",
               "rpart",                                                 # For Decision Tree
               "rattle", "rpart.plot",                                  # For fancyRpartPlot
               "visNetwork", "sparkline"                                # For visTree
)

               

UB <- fread(paste(getwd(), "Universal Bank_Main.csv", sep = "/"))       # 데이터 불러오기

UB %>%
  as_tibble
```

----------

# **2. 데이터 전처리**

```{r}
UB %<>%
  data.frame() %>%                                                      # Data Frame 형태로 변환
  select(-1)                                                            # ID 변수 제거

# Convert to Factor
fac.col <- c("Family", "Education", "Securities.Account", 
             "CD.Account", "Online", "CreditCard",
             # Target
             "Personal.Loan")

UB <- UB %>% 
  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환

glimpse(UB)                                                             # 데이터 구조 확인
```

----------

# **3. 데이터 탐색**

```{r}
ggpairs(UB,                                           
        columns = c("Age", "Experience", "Income",        # 수치형 예측 변수
                    "ZIP.Code", "CCAvg", "Mortgage"),                            
        aes(colour = Personal.Loan)) +                    # Target의 범주에 따라 색깔을 다르게 표현
  theme_bw()

ggpairs(UB,                                           
        columns = c("Age", "Experience", "Income",        # 수치형 예측 변수
                    "ZIP.Code", "CCAvg", "Mortgage"), 
        aes(colour = Personal.Loan), alpha = 0.8) +       # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#00798c", "#d1495b")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#00798c", "#d1495b")) +   # 특정 색깔 지정
  theme_bw()

ggpairs(UB,                                           
        columns = c("Age", "Income",                      # 수치형 예측 변수
                    "Family", "Education"),               # 범주형 예측 변수
        aes(colour = Personal.Loan, alpha = 0.8)) +       # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#E69F00", "#56B4E9")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#E69F00", "#56B4E9")) +   # 특정 색깔 지정
  theme_bw()
```

----------

# **4. 데이터 분할**

```{r}
# Partition (Training Dataset : Test Dataset = 7:3)
y      <- UB$Personal.Loan                            # Target
 
set.seed(200)
ind    <- createDataPartition(y, p = 0.7, list = T)   # Index를 이용하여 7:3으로 분할
UB.trd <- UB[ind$Resample1,]                          # Training Dataset
UB.ted <- UB[-ind$Resample1,]                         # Test Dataset
```

----------

# **5. 모형 훈련**

Package `"rpart"`는 수정된 CART를 알고리듬으로 사용하며, `CP` (Complexity Parameter)를 이용하여 최적의 모형을 찾아낸다. `CP`는 최적의 나무 크기를 찾기 위한 모수로써, 노드를 분할할 때 분할 전과 비교하여 오분류율이 `CP` 값 이상으로 향상되지 않으면 분할을 멈춘다. 최적의 모형을 얻기 위해 필요한 `CP`는 Cross Validation (CV) 기법을 이용하여 얻을 수 있으며, 해당 Package에서는 기본값으로 10-Fold CV를 이용한다. 마지막으로, Package `"rpart"`는 가독성 좋은 그래프로 결과를 표현할 수 있어 의사결정나무를 시각화하기에 좋은 Package이다.

```{r, eval=FALSE}
rpart(formula, data, method, ...)
```

- `formula` : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 `Target ~ 예측 변수`의 형태로 표현한다.
- `data` : `formula`에 포함하고 있는 변수들의 데이터셋(Data Frame)
-  `method` : Target이 범주형이면 `"class"`, 그렇지 않으면 `"anova"`를 입력한다.

```{r}
set.seed(200)                             # For CV
rContol      <- rpart.control(xval = 5)   # xval : xval-Fold CV
UB.trd.rtree <- rpart(Personal.Loan ~ ., data = UB.trd,                 
                      method = "class",   
                      control = rContol)         

summary(UB.trd.rtree)
```

`Result!` 첫 번째 Table에서,

- `CP` : Complexity Parameter로 Training Dataset에 대한 오분류율과 나무 크기에 대한 패널티를 이용하여 아래와 같이 계산한다. 
$$ 
\begin{align*}
cp = \frac{p(\text{incorrect}_{l}) - p(\text{incorrect}_{l+1})}{n(\text{splits}_{l+1}) - n(\text{splits}_{l})}. 
\end{align*}
$$
    - $p(\text{incorrect}_{l})$ : 현재 Depth에서 오분류율
    - $n(\text{splits}_{l})$ :현재 Depth에서 분할 횟수
    - $p(\text{incorrect}_{l+1})$ : 다음 Depth에서 오분류율
    - $n(\text{splits}_{l+1})$ :다음 Depth에서 분할 횟수   
예를 들어, 첫 번째 분할에서 `CP`값은 다음과 같다.

$$ cp = \frac{1.00-0.35}{2-0} = 0.325 $$

- `nsplit` : 분할 횟수
- `rel error` : 현재 Depth에서 잘못 분류된 Case들의 비율(오분류율)
- `xerror` : CV에 대한 오차
- `xstd` : `xerror`의 표준오차

두 번째 Table `Variable importance`은 변수 중요도에 대한 결과이며, 수치가 높을수록 중요한 변수임을 의미한다.  

----------

# **6. Tree Plot**

## **6-1. "fancyRpartPlot"**

```{r}
fancyRpartPlot(UB.trd.rtree)                  # Plot
```

</br>

## **6-2. "visTree"**

```{r}
visTree(UB.trd.rtree)                        # Network-based Plot 
```


----------

# **7. 가지치기**

가지치기(Pruning)는 생성된 가지를 잘라내어 모형을 단순화하는 과정을 의미한다. 의사결정나무 학습에서는 Training Dataset을 이용하여 노드에 대한 분할과정이 최대한 정확한 분류를 위해 계속 반복된다. 하지만, 과도한 반복은 많은 가지를 생성하게 되어 모형이 복잡해지고, 결과적으로 과대적합이 발생할 수 있다. 여기서 과대적합은 Training Dataset에 대해서는 정확하게 분류하지만 새로운 데이터셋인 Test Dataset에 대해서는 예측 성능이 현저히 떨어지는 현상을 의미한다. 따라서 의사결정나무는 가지치기를 통해 모형을 단순화하고 과대적합을 방지하는 과정이 필요하다.  
Package `"rpart"`에서는 `CP`의 최적값을 이용하여 가지치기를 수행할 수 있다. 함수 `rpart()`를 이용하여 얻은 위의 결과를 기반으로 `xerror`가 최소가 되는 `CP`를 가지는 트리 모형을 생성한다.

```{r}
table              <- UB.trd.rtree$cptable               # CP Table

low.error          <- which.min(table[ , "xerror"])      # min("xerror")에 해당하는 Index 추출
cp.best            <- table[low.error, "CP"]             # min("xerror")에 해당하는 CP 값(CP의 최적값) 추출

# 가지치기 수행
UB.trd.prune.rtree <- prune(UB.trd.rtree, cp = cp.best)  # prune(트리 모형, CP의 최적값)

UB.trd.prune.rtree$cptable                               # Best 모형의 CP Table	

```

<br />


```{r} 
fancyRpartPlot(UB.trd.prune.rtree)                       # Plot            
```

<br />

```{r} 
visTree(UB.trd.prune.rtree)                              # Network-based Plot 
```

----------


# **8. 모형 평가**

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률` 이 필요하며, 함수 `predict()`를 이용하여 생성한다. 
```{r}
# 예측 class 생성 
test.rtree.class <- predict(UB.trd.prune.rtree,
                            newdata = UB.ted[,-9],     # Test Dataset including Only 예측 변수   
                            type = "class")            # 예측 class 생성       

test.rtree.class %>%
  as_tibble
```

<br />

## **8-1. ConfusionMatrix**

```{r}
CM   <- caret::confusionMatrix(test.rtree.class, UB.ted$Personal.Loan, 
                               positive = "1")         # confusionMatrix(예측 class, 실제 class, positive = "관심 class")
CM
```

<br />

## **8-2. ROC 곡선**

```{r}
# 예측 확률 생성
test.rtree.prob <- predict(UB.trd.prune.rtree, 
                           newdata = UB.ted[,-9],      # Test Dataset including Only 예측 변수  
                           type = "prob")              # 예측 확률 생성     

test.rtree.prob %>%
  as_tibble
```

```{r}
test.rtree.prob <- test.rtree.prob[,2]                 # "Personal.Loan = 1"에 대한 예측 확률

ac  <- UB.ted$Personal.Loan                            # Test Dataset의 실제 class 
pp  <- as.numeric(test.rtree.prob)                     # 예측 확률을 수치형으로 변환
```

### **1) Package "pROC"**

```{r}
pacman::p_load("pROC")

rtree.roc  <- roc(ac, pp, plot = T, col = "gray")      # roc(실제 class, 예측 확률)
auc        <- round(auc(rtree.roc), 3)
legend("bottomright", legend = auc, bty = "n")

```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(rtree.roc,   
         col="gray",                                   # Line Color
         print.auc = TRUE,                             # AUC 출력 여부
         print.auc.col = "red",                        # AUC 글씨 색깔
         print.thres = TRUE,                           # Cutoff Value 출력 여부
         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                      # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                   # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(rtree.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```



### **2) Package "Epi"**

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                              # ROC(예측 확률, 실제 class)  

```

### **3) Package "ROCR"**

```{r}
pacman::p_load("ROCR")

rtree.pred <- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) 

rtree.perf <- performance(rtree.pred, "tpr", "fpr")    # performance(, "민감도", "1-특이도")                      
plot(rtree.perf, col = "gray")                         # ROC Curve

perf.auc   <- performance(rtree.pred, "auc")           # AUC
auc        <- attributes(perf.auc)$y.values
legend("bottomright", legend = auc, bty = "n")
```

<br />

## **8-3. 향상 차트**

### **1) Package "ROCR"**

```{r}
rtree.perf <- performance(rtree.pred, "lift", "rpp")   # Lift Chart                      
plot(rtree.perf, main = "lift curve",
     colorize = T,                                     # Coloring according to cutoff 
     lwd = 2) 

```


```{r, eval=F, echo=F, include=FALSE}
#### **2) Package "lift"**

pacman::p_load("lift")

plotLift(test.rtree.prob, UB.ted$Personal.Loan, cumulative = T, n.buckets = 24) # plotLift(8-2에서 생성한 예측 확률, 실제 class)
TopDecileLift(test.rtree.prob, UB.ted$Personal.Loan)		                        # Top 10%의 향상도 출력

```
