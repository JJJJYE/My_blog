---
title: "Boosting based on Caret"
description: |
   R code using Caret Package for Various Models of Boosting
author:
  - name: Yeongeun Jeon
  - name: Jeongwook Lee
  - name: Jung In Seo
date: 11-01-2020
preview: preview.PNG
categories: Machine Learning
output: 
  distill::distill_article:
        toc: TRUE
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
	                    message = FALSE,
	                    warning = FALSE)
```

> Package `"caret"`은 다양한 머신러닝 분석을 하나로 모은 패키지이며, `trainControl`을 이용하여 과적합을 방지할 수 있다. `"caret"`에서는 Boosting을 이용한 다양한 기법을 수행할 수 있으며, 그 중 가장 많이 쓰이는 `AdaBoost`, `Gradient Boosting`, `XGBoost`를 이용하여 예제 데이터를 분석한다. 
예제 데이터는 "Universal Bank_Main"로 유니버셜 은행의 고객들에 대한 데이터(출처 : Data Mining for Business Intelligence, Shmueli et al. 2010)이다. 데이터는 총 2500개이며, 변수의 갯수는 13개이다. 여기서 **Target**은 `Person.Loan`이다.


<center><img src="./image/그림1.png" width="600" height="600"></center>

<br />


<center><img src="./image/표.png" width="400" height="400"></center>


----------

# **1. 데이터 불러오기**

```{r}
pacman::p_load("data.table", "dplyr") 

UB   <- fread(paste(getwd(),"Universal Bank_Main.csv", sep="/")) %>%   # 데이터 불러오기
  data.frame() %>%                                                     # Data frame 변환
  mutate(Personal.Loan = ifelse(Personal.Loan==1, "yes","no")) %>%     # Character for classification
  select(-1)                                                           # ID변수 제거



cols <- c("Family", "Education", "Personal.Loan", "Securities.Account", 
          "CD.Account", "Online", "CreditCard")

UB   <- UB %>% 
  mutate_at(cols, as.factor)                                          # 범주형 변수 변환
 
glimpse(UB)                                                           # 데이터 구조

```


-----------

# **2. 데이터 분할**

```{r}
pacman::p_load("caret")
# Partition (Traning Data : Test Data = 7:3)
y      <- UB$Personal.Loan                       # Target

set.seed(200)
ind    <- createDataPartition(y, p=0.7, list=F)  # Training Data를 70% 추출

UB.trd <- UB[ind,]                               # Traning Data

UB.ted <- UB[-ind,]                              # Test Data


```


----------

# **3. AdaBoost**
## **3-1. 최적의 모수 찾기**

>Boosting에서 가장 많이 쓰이는 AdaBoost의 최적의 모수를 찾기 위해서 `"Random Search"` 방법을 먼저 수행하였다.


```{r}
fitControl <- trainControl(method = "cv", number = 5, search = "random")    # 5-Fold-Cross Validation

```

```{r}
set.seed(100)                                                          # seed 고정 For Cross Validation
caret.rd.ada <- train(Personal.Loan~., data = UB.trd,
                      method = "AdaBoost.M1", trControl = fitControl,   
                      tuneLength = 5)                                  # tuneLength (탐색할 후보 모수 갯수) 

caret.rd.ada
```

- Tune Parameter
   - `mfinal` : 반복 수
   - `maxdepth` : Tree의 최대 깊이
   - `coeflearn` : 가중치 업데이트 계수

```{r}
plot(caret.rd.ada)                            # Accuracy 
```

- `maxdepth` = 6, `mfinal` = 23, `coeflearn` = "Zhu"일 때 정확도가 가장 높다.
- `mfinal` = 23을 기준으로 다양한 후보 모수를 주며 `Grid Search` 방법으로 최적의 모수를 찾는다.

```{r}
fitControl <- trainControl(method = "cv", number = 5)         # 5-Fold-Cross Validation


customGrid <- expand.grid(mfinal    = seq(22, 24, by = 1),    # Random Search의 Best Parameter 기준으로 탐색
                          maxdepth  = 1,                      # Stump를 생성하기 위해 최대 깊이 "1"로 고정
                          coeflearn = "Breiman")              # 가장 많이 쓰이는 Breiman로 고정     
```


```{r}
set.seed(100)  # seed 고정 For Cross Validation
caret.gd.ada <- train(Personal.Loan~., data = UB.trd, method = "AdaBoost.M1",  
                      trControl = fitControl, tuneGrid = customGrid)    

caret.gd.ada
```

```{r}
plot(caret.gd.ada)            # Accuracy
```

-  `maxdepth` = 1, `mfinal` = 23, `coeflearn` = "Breiman"일 때 가장 높다.


### **3-1-1. 변수 중요도**


```{r}
# 변수 중요도
adaImp <- varImp(caret.gd.ada, scale = FALSE)
plot(adaImp)
```


### **3-1-2. 가중치**

```{r}
caret.gd.ada$finalModel$weights						 # 각 Tree에 대한 정보의 양
```



----------

## **3-2. 모형 평가**

```{r}
# 적합된 모형으로 Test Data의 클래스 예측
caret.gd.ada.pred <- predict(caret.gd.ada, newdata = UB.ted) 			# predict(AdaBoost모형, Test Data)
```

### **3-2-1. ConfusionMatrix**

```{r}
confusionMatrix(caret.gd.ada.pred, UB.ted$Personal.Loan, positive = "yes")  # confusionMatrix(예측 클래스, 실제 클래스, positive = "관심 클래스")

```

<br />

### **3-2-2. ROC 곡선**


#### **1) Package "pROC"**

```{r}
pacman::p_load("pROC")                          

test.ada.prob <- predict(caret.gd.ada, newdata = UB.ted, type = "prob")  # Training Data로 적합시킨 모형에 대한 Test Data의 각 클래스에 대한 예측 확률

test.ada.prob <- test.ada.prob[,2]                                       # "yes"에 대한 예측 확률


ac           <- UB.ted$Personal.Loan                                     # 실제 클래스

pp           <- as.numeric(test.ada.prob)                                # "yes"에 대한 예측 확률


ada.roc     <- roc(ac, pp, plot = T, col = "red")                        # roc(실제 클래스, 예측 확률)

auc <- round(auc(ada.roc), 3)                                            # AUC 
legend("bottomright",legend = auc, bty = "n")

detach(package:pROC)
```

<br />

#### **2) Package "Epi"**

```{r}
pacman::p_load("Epi")                        
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp,ac, plot="ROC")       # ROC(예측 확률 , 실제 클래스)                                

detach(package:Epi)

```

<br />

#### **3) Package "ROCR"**

```{r}
pacman::p_load("ROCR")                      

ada.pred <- prediction(pp, ac)                      # prediction(예측 확률, 실제 클래스)

ada.perf <- performance(ada.pred, "tpr", "fpr")     # performance(, "민감도", "1-특이도")                      
plot(ada.perf, col = "red")                         # ROC Curve
abline(0,1, col = "black")


perf.auc <- performance(ada.pred, "auc")            # AUC        

auc <- attributes(perf.auc)$y.values                  
legend("bottomright",legend = auc,bty = "n") 

```

<br />


### **3-2-3. 향상 차트**


#### **1) Package "ROCR"**

```{r}
ada.lift <- performance(ada.pred,"lift", "rpp")      # Lift chart
plot(ada.lift, colorize = T, lwd = 2)			


detach(package:ROCR)
```

<br />

#### **2) Package "lift"**

```{r}
pacman::p_load("lift")

ac.numeric <- ifelse(UB.ted$Personal.Loan=="yes",1,0)     # 실제 클래스를 수치형으로 변환

plotLift(pp, ac.numeric, cumulative = T, n.buckets = 24)  # plotLift(예측 확률, 실제 클래스)

TopDecileLift(pp, ac.numeric)                             # Top 10% 향상도 출력

detach(package:lift)
```


----------


# **4. Gradient Boosting**
## **4-1. 최적의 모수 찾기**

>Boosting에서 가장 많이 쓰이는 Gradient Boosting의 최적의 모수를 찾기 위해서  `"Random Search"` 방법을 먼저 수행하였다.


```{r}
fitControl <- trainControl(method = "cv", number = 5, search = "random")    # 5-Fold-Cross Validation

```

```{r}
set.seed(100)                                                  # seed 고정 For Cross Validation
caret.rd.gbm <- train(Personal.Loan~., data = UB.trd,
                      method = "gbm", trControl = fitControl,  
                      tuneLength = 5, verbose=F)               # tuneLength (탐색할 후보 모수 갯수) 

caret.rd.gbm 
```


- Tune Parameter 
   - `n.trees` : 반복 수
   - `interaction.depth` : Tree의 최대 깊이
   - `shrinkage` : Learning Rate
   - `n.minobsinnode` : Terminal node의 최소 관측갯수

- `n.trees` = 2343, `interaction.depth` = 6, `shrinkage` = 0.2151574, `n.minobsinnode` = 16일 때 정확도가 가장 높다.
- `n.trees` = 2343, `interaction.depth` = 6, `shrinkage` = 0.2151574, `n.minobsinnode` = 16을 기준으로 다양한 후보 모수를 주며 `Grid Search` 방법으로 최적의 모수를 찾는다.

```{r}
fitControl <- trainControl(method = "cv", number = 5)                       # 5-Fold-Cross Validation


customGrid <- expand.grid(n.trees           = seq(2343, 2344, by = 1),      # Random Search의 Best Parameter 기준으로 탐색
                          interaction.depth = seq(6, 7, by = 1),
                          shrinkage         = seq(0.21, 0.22, by = 0.01),
                          n.minobsinnode    = seq(16, 17, by = 1))


```


```{r}
set.seed(100)             # seed 고정 For Cross Validation
caret.gd.gbm <- train(Personal.Loan~., data = UB.trd, method = "gbm",   
                      trControl = fitControl, tuneGrid = customGrid, verbose=F)    

caret.gd.gbm
```


- `n.trees` = 2343, `interaction.depth` = 7, `shrinkage` = 0.21, `n.minobsinnode` = 16일 때 가장 높으며, 정확도는 약간 증가했다.


```{r}
# 최종 모형
caret.gd.gbm$finalModel                                                 
```


### **4-1-1. 변수 중요도**

```{r}
summary(caret.gd.gbm$finalModel, cBars = 10, las=2)         # cBars : 상위 몇개 나타낼 것인지 
```



----------

## **4-2. 모형 평가**

```{r}
# 적합된 모형으로 Test Data의 클래스 예측
caret.gd.gbm.pred <- predict(caret.gd.gbm, newdata=UB.ted) 			# predict(gbm모형, Test Data)

```

### **4-2-1. ConfusionMatrix**

```{r}
confusionMatrix(caret.gd.gbm.pred, UB.ted$Personal.Loan, positive = "yes")  # confusionMatrix(예측 클래스, 실제 클래스, positive = "관심 클래스")

```

<br />

### **4-2-2. ROC 곡선**


#### **1) Package "pROC"**

```{r}
pacman::p_load("pROC")                          

test.gbm.prob <- predict(caret.gd.gbm, newdata = UB.ted, type = "prob")  # Training Data로 적합시킨 모형에 대한 Test Data의 각 클래스에 대한 예측 확률

test.gbm.prob <- test.gbm.prob[,2]                                       # "yes"에 대한 예측 확률


ac           <- UB.ted$Personal.Loan                                     # 실제 클래스

pp           <- as.numeric(test.gbm.prob)                                # "yes"에 대한 예측 확률


gbm.roc      <- roc(ac, pp, plot = T, col = "red")                       # roc(실제 클래스, 예측 확률)

auc          <- round(auc(gbm.roc), 3)                                   # AUC 
legend("bottomright",legend = auc, bty = "n")

detach(package:pROC)
```

<br />

#### **2) Package "Epi"**

```{r}
pacman::p_load("Epi")                        
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp,ac, plot="ROC")       # ROC(예측 확률 , 실제 클래스)                                

detach(package:Epi)

```

<br />

#### **3) Package "ROCR"**

```{r}
pacman::p_load("ROCR")                                                  

gbm.pred <- prediction(pp, ac)                      # prediction(예측 확률, 실제 클래스)

gbm.perf <- performance(gbm.pred, "tpr", "fpr")     # performance(, "민감도", "1-특이도")                      
plot(gbm.perf, col="red")                           # ROC Curve
abline(0,1, col="black")


perf.auc <- performance(gbm.pred, "auc")            # AUC        

auc <- attributes(perf.auc)$y.values                  
legend("bottomright",legend = auc,bty = "n") 

```

<br />


### **4-2-3. 향상 차트**


#### **1) Package "ROCR"**

```{r}
gbm.lift <- performance(gbm.pred,"lift", "rpp")      # Lift chart
plot(gbm.lift, colorize = T, lwd = 2)			
	

detach(package:ROCR)
```

<br />

#### **2) Package "lift"**

```{r}
pacman::p_load("lift")

ac.numeric <- ifelse(UB.ted$Personal.Loan=="yes",1,0)     # 실제 클래스를 수치형으로 변환

plotLift(pp, ac.numeric, cumulative = T, n.buckets =24)   # plotLift(예측 확률, 실제 클래스)

TopDecileLift(pp, ac.numeric)                             # Top 10% 향상도 출력

detach(package:lift)
```

----------


# **5. XGBoost**
## **5-1. 최적의 모수 찾기**

>Gradient Boosting에서 확장된 XGBoost의 최적의 모수를 찾기 위해서  `"Random Search"` 방법을 먼저 수행하였다.


```{r}
fitControl <- trainControl(method = "cv", number = 5, search = "random")    # 5-Fold-Cross Validation

```

```{r}
set.seed(100)                                                      # seed 고정 For Cross Validation
caret.rd.xgb <- train(Personal.Loan~., data = UB.trd,
                      method = "xgbTree", trControl = fitControl,   
                      tuneLength = 5,                              # tuneLength (탐색할 후보 모수 갯수)
                      lambda = 0)                                  # Regularization Parameter

caret.rd.xgb 
```

- Tune Parameter 
   - `nrounds` : 반복 수
   - `max_depth` : Tree의 최대 깊이
   - `eta` : Learning Late
   - `gamma` : 분할하기 위해 필요한 최소 손실 감소, 클수록 분할이 쉽게 일어나지 않음
   - `colsample_bytree` : Tree 생성 때 사용할 예측변수 비율 
   - `min_child_weight` : 한 leaf 노드에 요구되는 관측치에 대한 가중치의 최소 합
   - `subsample` : 모델 구축시 사용할 Data비율로 1이면 전체 Data 사용

- `nrounds` = 624, `max_depth` = 6, `eta` = 0.2151574, `gamma` = 5.383487, `colsample_bytree` = 0.6527814,  `min_child_weight` = 3,  `subsample` = 0.9921731일 때 정확도가 가장 높다.
- `nrounds` = 624, `max_depth` = 6, `eta` = 0.2151574, `gamma` = 5.383487, `colsample_bytree` = 0.6527814,  `min_child_weight` = 3,  `subsample` = 0.9921731을 기준으로 다양한 후보 모수를 주며 `Grid Search` 방법으로 최적의 모수를 찾는다.

```{r}
fitControl <- trainControl(method = "cv", number = 5)                       # 5-Fold-Cross Validation


customGrid <- expand.grid(nrounds          = seq(624, 625, by = 1),         # Random Search의 Best Parameter 기준으로 탐색
                          max_depth        = seq(6, 7, by = 1),
                          eta              = seq(0.2, 0.3, by = 0.1),
                          gamma            = seq(5.3, 5.4, by = 0.1),
                          colsample_bytree = seq(0.6, 0.7, by = 0.1),
                          min_child_weight = seq(3, 4, by = 1),
                          subsample        = seq(0.9, 1, by = 0.1))

```


```{r}
set.seed(100)                                                              # seed 고정 For Cross Validation
caret.gd.xgb <- train(Personal.Loan~., data = UB.trd, method = "xgbTree",  
                      trControl = fitControl, tuneGrid = customGrid,
                      lambda = 0)                                          # Regularization Parameter    

caret.gd.xgb
```

- `nrounds` = 624, `max_depth` = 7, `eta` = 0.3, `gamma` = 5.3, `colsample_bytree` = 0.7,  `min_child_weight` = 3,  `subsample` = 1일 때 가장 높다.


### **5-1-1. 변수 중요도**

```{r}
xgbImp <- varImp(caret.gd.xgb, scale = FALSE)
plot(xgbImp)
```


----------

## **5-2. 모형 평가**

```{r}
# 적합된 모형으로 Test Data의 클래스 예측
caret.gd.xgb.pred <- predict(caret.gd.xgb, newdata=UB.ted) 			# predict(xgboost모형, Test Data)

```

### **5-2-1. ConfusionMatrix**

```{r}
confusionMatrix(caret.gd.xgb.pred, UB.ted$Personal.Loan, positive = "yes")  # confusionMatrix(예측 클래스, 실제 클래스, positive = "관심 클래스")

```

<br />

### **5-2-2. ROC 곡선**


#### **1) Package "pROC"**

```{r}
pacman::p_load("pROC")                          

test.xgb.prob <- predict(caret.gd.xgb, newdata = UB.ted, type = "prob")  # Training Data로 적합시킨 모형에 대한 Test Data의 각 클래스에 대한 예측 확률

test.xgb.prob <- test.xgb.prob[,2]                                       # "yes"에 대한 예측 확률


ac           <- UB.ted$Personal.Loan                                     # 실제 클래스

pp           <- as.numeric(test.xgb.prob)                                # "yes"에 대한 예측 확률


xgb.roc      <- roc(ac, pp, plot = T, col = "red")                       # roc(실제 클래스, 예측 확률)

auc          <- round(auc(xgb.roc), 3)                                   # AUC 
legend("bottomright",legend = auc, bty = "n")

detach(package:pROC)
```

<br />

#### **2) Package "Epi"**

```{r}
pacman::p_load("Epi")                        
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp,ac, plot="ROC")       # ROC(예측 확률 , 실제 클래스)                                

detach(package:Epi)

```

<br />

#### **3) Package "ROCR"**

```{r}
pacman::p_load("ROCR")                      

xgb.pred <- prediction(pp, ac)                      # prediction(예측 확률, 실제 클래스)

xgb.perf <- performance(xgb.pred, "tpr", "fpr")     # performance(, "민감도", "1-특이도")                      
plot(xgb.perf, col = "red")                         # ROC Curve
abline(0,1, col = "black")


perf.auc <- performance(xgb.pred, "auc")            # AUC        

auc <- attributes(perf.auc)$y.values                  
legend("bottomright",legend = auc,bty = "n") 
```

<br />


### **5-2-3. 향상 차트**


#### **1) Package "ROCR"**

```{r}
xgb.lift <- performance(xgb.pred,"lift", "rpp")      # Lift chart
plot(xgb.lift, colorize = T, lwd = 2)			


detach(package:ROCR)
```

<br />

#### **2) Package "lift"**

```{r}
pacman::p_load("lift")

ac.numeric <- ifelse(UB.ted$Personal.Loan=="yes",1,0)     # 실제 클래스를 수치형으로 변환

plotLift(pp, ac.numeric, cumulative = T, n.buckets = 24)  # plotLift(예측 확률, 실제 클래스)
TopDecileLift(pp, ac.numeric)                             # Top 10% 향상도 출력

detach(package:lift)
```


----------

# **6. 모형 비교**

```{r}
plot(ada.roc, col="red")         # ROC Curve
par(new=TRUE)
plot(gbm.roc, col="green")       # ROC Curve
par(new=TRUE)
plot(xgb.roc, col="orange")      # ROC Curve

legend("bottomright", legend=c( "AdaBoost", "GBM", "XGBoost" ),
       col=c( "red", "green", "orange"), lty=c(1,1,1))

```

