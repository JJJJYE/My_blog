---
title: "Permutation Importance"
description: |
  R code Description for Permutation Importance of Machine Learning 
author:
  - name: Yeongeun Jeon
  - name: Jung In Seo
date: 06-14-2022
preview: preview.PNG
categories: Machine Learning
output: 
  distill::distill_article:
        toc: TRUE
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}

p, ul, li{
text-align: justify
}

```


> Package `DALEX`는 순열(Permutation)을 이용하여 변수 중요도를 측정하는 함수들을 포함하고 있다. 순열에 기반한 변수 중요도는 모형을 학습한 후 특정 예측변수의 값을 `Permutation(= 랜덤하게 섞은)`한 데이터를 이용하여 측정된 예측 성능과 `원래 데이터`를 이용하여 측정된 예측 성능을 비교하여 해당 예측변수의 영향력을 확인한다. 만약, 특정 예측변수가 중요하다면(영향력이 크다면), 해당 예측변수의 값들을 Permutation한 후에 측정한 예측 성능은 원래 데이터를 이용한 예측 성능보다 크게 감소한다. 반면, 특정 예측변수가 중요하지 않다면, 해당 예측변수의 값들을 Permutation한 후에 측정한 예측 성능은 차이가 거의 없거나 오히려 증가한다. 이러한 변수 중요도 측정 방법은 모형 구조에 어떠한 가정도 하지 않기 때문에 `어떤 모형이든지` 쉽게 변수 중요도를 측정하여 비교할 수 있으며, 중요도를 계산하기 위해 모형을 재학습할 필요가 없다는 장점을 가지고 있다. 

  ![[출처 : https://www.kaggle.com/code/dansbecker/permutation-importance/tutorial](https://www.kaggle.com/code/dansbecker/permutation-importance/tutorial)](image/shuffle.png){width=90%}


> Package `caret`을 이용하여 `Random Forest`와 `XGBoost`를 수행하고 순열에 기반한 변수 중요도를 적용하는 방법을 설명하기 위해  예제 데이터셋 "Heart Disease Prediction"를 사용한다. 이 데이터는 환자의 심장병을 예측하는 데이터(출처 : Package MLDataR, Gary Hutson 2021)로 총 918명의 환자에 대한 자료이며, 변수는 총 10개이다. 여기서 **Target**은 `HeartDisease`이다.

<center>
  ![](image/그림1.png){width=85%}
</center>

<br />

<center>
  ![](image/표.png){width=70%}
</center>

----------

# **1. 데이터 불러오기**

```{r}
pacman::p_load("MLDataR",                                              # For Data
               "data.table", "magrittr", "dplyr",
               "caret",                                                # For ML
               "DALEX",                                                # For VIM
               "doParallel", "parallel")

registerDoParallel(cores=detectCores())


data(heartdisease)
data <- heartdisease 


cols <- c("Sex", "RestingECG", "Angina", "HeartDisease")

data   <- data %>% 
  mutate_at(cols, as.factor)                                           

glimpse(data)                                                       

```

-----------

# **2. 데이터 분할**

```{r}
set.seed(100)                                                          
trainIndex <- createDataPartition(data$HeartDisease, 
                                  p = .8, 
                                  list = FALSE)
HD.train <- data[ trainIndex,]
HD.test  <- data[-trainIndex,]
```

-----------

# **3. 머신러닝 분석**

- 예제 데이터에 머신러닝 방법을 적용하기 위해 Package `caret`을 이용한다.

```{r}

set.seed(100)
fitControl <- trainControl(method = "adaptive_cv",
                           number = 5,
                           repeats = 5,
                           adaptive = list(min = 5,
                                           alpha = 0.05,
                                           method = "BT",
                                           complete = TRUE),
                           search = "random",
                           allowParallel = TRUE) 
```

-----------

## **3-1. Random Forest**

```{r}
set.seed(100)                                                         
caret.rf <- caret::train(HeartDisease~., data = HD.train, 
                         method = "parRF",                       
                         trControl = fitControl,
                         tuneLength = 2,                              
                         importance = TRUE)   
caret.rf
caret.rf$finalModel
```

-----------

## **3-2. XGBoost**

```{r}
set.seed(100)                                                         
caret.xgb <- caret::train(HeartDisease~., data = HD.train, 
                         method = "xgbTree",          
                         trControl = fitControl,
                         tuneLength = 2)                              

caret.xgb
caret.xgb$finalModel
```


-----------

# **4. 순열 중요도**

- Package `DALEX`를 이용하면 순열에 기반한 변수 중요도의 결과를 그래프로 나타내어 어떤 변수가 중요한지 이해하기 쉬우며, 여러 모형의 변수 중요도 결과를 하나의 그래프로 나타낼 수 있어 모형 간에 변수 중요도 결과를 쉽게 비교할 수 있다.

-----------

## **4-1. 함수 explain()**

- 순열에 기반한 변수 중요도를 수행하기 전에 먼저 함수 `explain()`을 이용하여 모형에 대한 설명(Model Explainer)을 정의한다.
- 함수 `explain()`의 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/DALEX/versions/2.4.1/topics/explain.default)를 참조한다.

```{r, eval = FALSE}
explain(model, data, y, label, type)
```

- `model` : 학습 모형
- `data` : Data Frame 또는 행렬로, 순열에 기반한 변수 중요도 척도값을 계산하기 위해 사용되는 데이터
    - `Target`은 제외
- `y` : `data`의 `Target`에 해당하는 수치형 벡터
- `label` : 모형의 이름
- `type` : 모형의 타입(classification / regression)


```{r}
Exp_rf <- DALEX::explain(model = caret.rf, 
                         data = HD.test[, -10],                       # Data except for Target 
                         y = as.numeric(HD.test$HeartDisease),        # Target : Numeric Type
                         label = "RF")
  
Exp_xgb <- DALEX::explain(model = caret.xgb, 
                         data = HD.test[, -10],                       # Data except for Target
                         y = as.numeric(HD.test$HeartDisease),        # Target : Numeric 
                         label = "XGBoost")
```

-----------

## **4-2. 함수 model_parts()**

- 함수 `model_parts()`를 이용하여 순열에 기반한 변수 중요도값을 계산할 수 있으며, 알고리즘은 다음과 같다.
    - 특정 예측 변수에 대해, 원래 데이터를 이용한 손실 함수값과 원래 데이터를 Permutation한 후 계산한 손실 함수값을 비교하여 특정 예측 변수의 중요도값을 얻는다.

![[출처 : https://ema.drwhy.ai/featureImportance.html](https://ema.drwhy.ai/featureImportance.html)](image/process.png){width=100%}

- 함수 `model_parts()`의 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/DALEX/versions/2.3.0/topics/model_parts)를 참조한다.

```{r, eval = FALSE}
model_parts(explainer, loss_function, type, variables, B, N)
```

- `explainer` : 함수 `explain()`를 이용하여 정의한 객체
- `loss_function` : 손실 함수
    - `loss_cross_entropy`
    - `loss_accuracy`
    - `loss_one_minus_auc`
    - `loss_root_mean_square`
    - `loss_sum_of_squares`
- `type` : 변수 중요도 척도 종류
    - `raw` : 특정 예측변수의 값들을 Permutation한 후 계산한 손실 함수값
    - `difference` : 특정 예측변수의 값들을 Permutation한 후 계산한 손실 함수값 $-$ 원래 데이터를 이용하여 계산한 손실 함수값
    - `ratio` : 특정 예측변수의 값들을 Permutation한 후 계산한 손실 함수값 $/$ 원래 데이터를 이용하여 계산한 손실 함수값
- `variables` : 변수 중요도를 계산하고자 하는 예측변수
- `B` : 변수 중요도값을 계산하기 위해 사용하는 순열의 수
- `N` : 변수 중요도값을 계산하기 위해 사용하는 데이터의 개수
    - 기본값은 1,000이며, `N = NULL`을 하면 모든 데이터 사용

-----------

`Caution!` 함수 `model_parts()`의 [Github](https://github.com/ModelOriented/DALEX/blob/master/R/model_parts.R)에 있는 함수 `feature_importance()`의 자세한 구조는 [여기](https://rdrr.io/cran/ingredients/src/R/feature_importance.R)를 참조한다. 함수 `model_parts()`의 옵션 `type`에 기반하여 계산된 변수 중요도 척도값과 그래프에 대해 자세히 설명해보자.


### **4-2-1. type = raw**

```{r}
set.seed(100)
vip.B_rf    <- model_parts(explainer = Exp_rf,  
                           # loss_function = loss_cross_entropy,
                           type = "raw",                             # raw / ratio / difference
                           B = 5,                                    # B : # of permutations
                           N = NULL)                                 
vip.B_rf
```


```{r}
set.seed(100)
vip.B_xgb   <- model_parts(explainer = Exp_xgb,   
                           # loss_function = loss_cross_entropy,
                           type = "raw",                             # raw / ratio / difference
                           B = 5,                                    # B : # of permutations
                           N = NULL)                                 
vip.B_xgb
```

`Caution!` Option `B`는 "순열의 반복의 수"이다. 즉, `B = 5`이면 특정 예측변수 값들을 5번 Permutation하여 5개의 손실 함수값이 계산되고 이들의 평균값을 대표값으로 사용한다. Option `N`은 손실 함수값을 계산하기 위해 사용할 Test Data point의 개수를 지정하는데 사용한다. 예를 들어 `N = NULL`이면 Test Data의 모든 데이터를 이용하여 손실 함수값을 계산하고, `N = 100`이면 Test Data에서 랜덤하게 선택한 100개를 이용하여 손실 함수값을 계산한다. 따라서, Option `N`에 특정값을 지정하면 손실 함수값을 계산할 때마다 Test Data에서 랜덤하게 그 수만큼 데이터를 선택하여 손실 함수값을 계산한다.  
`Result!` `mean_dropout_loss`은 평균 손실 함수값을 의미한다. "_full_model_"의 `mean_dropout_loss`은 Permutation없이 Test Data를 이용하여 계산한 평균 손실 함수값을 의미하며, "_baseline_"의 `mean_dropout_loss`은 Test Data의 값들을 Permutation한 후 계산한 평균 손실 함수값이다. 


```{r}
plot(vip.B_rf, vip.B_xgb) +
    ggtitle("Mean variable-importance over 5 permutations", "") 
```

`Caution!` 함수 `plot()`은 Package `ggplot`을 이용하여 만들어진 함수이므로 `ggplot`의 다양한 옵션을 이용하여 그래프를 수정할 수 있다.  

`Result!` `X축`은 평균 손실 함수값이다. 막대(Bar)의 점선 수직선은 "_full_model_"의 `mean_dropout_loss`이며, 막대의 끝은 해당 예측변수 값을 Permutation한 후 계산된 평균 손실 함수값이다. 따라서, 막대의 길이는 해당 예측변수 값을 Permutation한 후 계산된 평균 손실 함수값과 "_full_model_"의 `mean_dropout_loss`의 차이를 나타낸다. 점선 수직선을 기준으로 막대가 오른쪽으로 길수록 그 차이가 크기 때문에 해당 예측변수가 그만큼 중요하다는 것을 나타낸다. 

-----------

### **4-2-2. type = difference**

```{r}
set.seed(100)
vip.B_rf    <- model_parts(explainer = Exp_rf,  
                           # loss_function = loss_cross_entropy,
                           type = "difference",                      # raw / ratio / difference
                           B = 5,                                    # B : # of permutations
                           N = NULL)                                 
vip.B_rf
```


```{r}
set.seed(100)
vip.B_xgb   <- model_parts(explainer = Exp_xgb,   
                           # loss_function = loss_cross_entropy,
                           type = "difference",                      # raw / ratio / difference
                           B = 5,                                    # B : # of permutations
                           N = NULL)                                 
vip.B_xgb
```

`Result!` `mean_dropout_loss`은 해당 예측변수 값을 Permutation한 후 계산된 평균 손실 함수값과 원래 Test Data의 Data Point를 통해 계산된 평균 손실 함수값의 `차이`를 의미한다. "_full_model_"의 `mean_dropout_loss`은 같은 값을 빼기 때문에 "0"이 된다.

`Result!` `mean_dropout_loss`은 Permutation없이 Test Data를 이용하여 계산한 평균 손실 함수값을 특정 예측변수의 값들을 Permutation한 후 계산한 평균 손실 함수값의  `차이`를 의미한다. "_full_model_"의 `mean_dropout_loss`은 동일한 값을 빼기 때문에 그 차이는 "0"이 된다.

```{r}
plot(vip.B_rf, vip.B_xgb) +
    ggtitle("Mean variable-importance over 5 permutations", "") 
```
 
`Result!` 막대(Bar)의 점선 수직선은 "_full_model_"의 `mean_dropout_loss`으로 0의 값을 가지며, 막대의 끝은 해당 예측변수의 값들을 Permutation한 후 계산한 평균 손실 함수값과 Permutation없이 계산한 평균 손실 함수값과의 차이이다. 따라서 점선 수직선을 기준으로 오른쪽으로 막대의 길이가 길수록 그 차이가 크다는 것을 의미하며, 이는 해당 예측변수가 중요하다는 것을 나타낸다. 

-----------

### **4-2-3. type = ratio**

```{r}
set.seed(100)
vip.B_rf    <- model_parts(explainer = Exp_rf,  
                           # loss_function = loss_cross_entropy,
                           type = "ratio",                           # raw / ratio / difference
                           B = 5,                                    # B : # of permutations
                           N = NULL)                                
vip.B_rf
```


```{r}
set.seed(100)
vip.B_xgb   <- model_parts(explainer = Exp_xgb,   
                           # loss_function = loss_cross_entropy,
                           type = "ratio",                           # raw / ratio / difference
                           B = 5,                                    # B : # of permutations
                           N = NULL)                                
vip.B_xgb
```

`Result!` `mean_dropout_loss`은 Permutation없이 계산한 평균 손실 함수값을 특정 예측변수의 값들을 Permutation한 후 계산한 평균 손실 함수값의  `비율`를 의미한다. "_full_model_"의 `mean_dropout_loss`은 동일한 값으로 나누기 때문에 그 비율은 "1"이 된다.

```{r}
plot(vip.B_rf, vip.B_xgb) +
    ggtitle("Mean variable-importance over 5 permutations", "") 
```

`Result!` 막대(Bar)의 점선 수직선은 "_full_model_"의 `mean_dropout_loss`으로 1의 값을 가지며, 막대의 끝은 해당 예측변수의 값들을 Permutation한 후 계산한 평균 손실 함수값과 Permutation없이 계산한 평균 손실 함수값과의 비율이다. 따라서 점선 수직선을 기준으로 오른쪽으로 막대의 길이가 길수록 해당 예측변수가 중요하다는 것을 나타낸다. 
    
    